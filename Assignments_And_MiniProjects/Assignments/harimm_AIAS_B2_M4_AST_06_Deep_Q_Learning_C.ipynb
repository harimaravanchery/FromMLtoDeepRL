{"cells":[{"cell_type":"markdown","metadata":{"id":"jqGbK5ZBg6Uf"},"source":["# Machine Learning and AI for Autonomous Systems\n","## A program by IISc and TalentSprint\n","### Assignment: Deep Q-Learning (DQN)"]},{"cell_type":"markdown","metadata":{"id":"AZbtiZbbHAOQ"},"source":["## Learning Objectives"]},{"cell_type":"markdown","metadata":{"id":"UL6Uy59UHAOR"},"source":["At the end of the experiment, you will be able to :\n","\n","* understand Q-learning\n","* differentiate between Q-learning and Deep Q-learning\n","* implement Deep Q-learning to solve Atari Ms-Pacman environment"]},{"cell_type":"markdown","metadata":{"id":"BNLA8HiKxQhc"},"source":["### Setup Steps:"]},{"cell_type":"code","metadata":{"id":"2YzfoPvJDiTX","executionInfo":{"status":"ok","timestamp":1720234638079,"user_tz":-330,"elapsed":623,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"source":["#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n","Id = \"2302794\" #@param {type:\"string\"}"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjoZJWGErxGf","executionInfo":{"status":"ok","timestamp":1720234641079,"user_tz":-330,"elapsed":2,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"source":["#@title Please enter your password (your registered phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n","password = \"9008710123\" #@param {type:\"string\"}"],"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":35},"id":"kxgfakokDUbI","outputId":"e06cb7b4-74ce-400c-a88d-0a8e88371902","executionInfo":{"status":"ok","timestamp":1720234766578,"user_tz":-330,"elapsed":122149,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2302794&recordId=1021\"></script>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Setup completed successfully\n"]}],"source":["#@title Run this cell to complete the setup for this Notebook\n","from IPython import get_ipython\n","\n","ipython = get_ipython()\n","\n","notebook= \"AIAS_B2_M4_AST_06_Deep_Q_Learning_C\" #name of the notebook\n","\n","def setup():\n","#  ipython.magic(\"sx pip3 install torch\")\n","    ipython.magic(\"sx wget https://files.grouplens.org/datasets/movielens/ml-25m.zip\")\n","    ipython.magic(\"sx unzip ml-25m.zip\")\n","    from IPython.display import HTML, display\n","    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n","    print(\"Setup completed successfully\")\n","    return\n","\n","def submit_notebook():\n","    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n","\n","    import requests, json, base64, datetime\n","\n","    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n","    if not submission_id:\n","      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","\n","      if r[\"status\"] == \"Success\":\n","          return r[\"record_id\"]\n","      elif \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print (\"Something is wrong, the notebook will not be submitted for grading\")\n","        return None\n","\n","    elif getAnswer() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n","      f = open(notebook + \".ipynb\", \"rb\")\n","      file_hash = base64.b64encode(f.read())\n","\n","      data = {\"complexity\" : Complexity, \"additional\" :Additional,\n","              \"concepts\" : Concepts, \"record_id\" : submission_id,\n","              \"answer\" : Answer, \"id\" : Id, \"file_hash\" : file_hash,\n","              \"notebook\" : notebook,\n","              \"feedback_experiments_input\" : Comments,\n","              \"feedback_mentor_support\": Mentor_support}\n","      r = requests.post(url, data = data)\n","      r = json.loads(r.text)\n","      if \"err\" in r:\n","        print(r[\"err\"])\n","        return None\n","      else:\n","        print(\"Your submission is successful.\")\n","        print(\"Ref Id:\", submission_id)\n","        print(\"Date of submission: \", r[\"date\"])\n","        print(\"Time of submission: \", r[\"time\"])\n","        print(\"View your submissions: https://aias-iisc.talentsprint.com/notebook_submissions\")\n","        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n","        return submission_id\n","    else: submission_id\n","\n","\n","def getAdditional():\n","  try:\n","    if not Additional:\n","      raise NameError\n","    else:\n","      return Additional\n","  except NameError:\n","    print (\"Please answer Additional Question\")\n","    return None\n","\n","def getComplexity():\n","  try:\n","    if not Complexity:\n","      raise NameError\n","    else:\n","      return Complexity\n","  except NameError:\n","    print (\"Please answer Complexity Question\")\n","    return None\n","\n","def getConcepts():\n","  try:\n","    if not Concepts:\n","      raise NameError\n","    else:\n","      return Concepts\n","  except NameError:\n","    print (\"Please answer Concepts Question\")\n","    return None\n","\n","\n","# def getWalkthrough():\n","#   try:\n","#     if not Walkthrough:\n","#       raise NameError\n","#     else:\n","#       return Walkthrough\n","#   except NameError:\n","#     print (\"Please answer Walkthrough Question\")\n","#     return None\n","\n","def getComments():\n","  try:\n","    if not Comments:\n","      raise NameError\n","    else:\n","      return Comments\n","  except NameError:\n","    print (\"Please answer Comments Question\")\n","    return None\n","\n","\n","def getMentorSupport():\n","  try:\n","    if not Mentor_support:\n","      raise NameError\n","    else:\n","      return Mentor_support\n","  except NameError:\n","    print (\"Please answer Mentor support Question\")\n","    return None\n","\n","def getAnswer():\n","  try:\n","    if not Answer:\n","      raise NameError\n","    else:\n","      return Answer\n","  except NameError:\n","    print (\"Please answer Question\")\n","    return None\n","\n","\n","def getId():\n","  try:\n","    return Id if Id else None\n","  except NameError:\n","    return None\n","\n","def getPassword():\n","  try:\n","    return password if password else None\n","  except NameError:\n","    return None\n","\n","submission_id = None\n","### Setup\n","if getPassword() and getId():\n","  submission_id = submit_notebook()\n","  if submission_id:\n","    setup()\n","else:\n","  print (\"Please complete Id and Password cells before running setup\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pXBOfzUYHAOR"},"source":["## Information"]},{"cell_type":"markdown","metadata":{"id":"bJrTyoGDHAOS"},"source":["**Q-Learning**\n","\n","The agent will perform the sequence of actions that will eventually generate the maximum total reward. This total reward is also called the **Q-value** and we will formalize our strategy as:\n","\n","$$Q(s, a) = r(s, a) + \\gamma\\ maxQ(s', a)$$\n","\n","The above equation states that the Q-value yielded from being at state $s$ and performing action $a$ is the immediate reward $r(s,a)$ plus the highest Q-value possible from the next state $s’$. Gamma here is the discount factor which controls the contribution of rewards further in the future.\n","\n","$Q(s’,a)$ depends on $Q(s”,a)$ which will then have a coefficient of gamma squared. So, the Q-value depends on Q-values of future states as shown here:\n","\n","$$Q(s, a) \\rightarrow \\gamma\\ Q(s', a) + \\gamma^2\\ Q(s'', a)\\ ...\\ ...\\ ...\\ \\gamma^n\\ Q(s''^{...n}, a)$$\n","\n","Adjusting the value of gamma will diminish or increase the contribution of future rewards.\n","\n","Since this is a recursive equation, we can start with making arbitrary assumptions for all q-values. With experience, it will converge to the optimal policy.\n","\n","To know more about Q-Learning, click [here](https://github.com/rishal-hurbans/Grokking-Artificial-Intelligence-Algorithms/tree/master/ch10-reinforcement_learning).\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"P-TzAn8XHAOT"},"source":["**Approximate Q-Learning and Deep Q-Learning**\n","\n","The main problem with Q-Learning is that it does not scale well to large (or even medium) Markov Decision Processes with many states and actions, and it is hard to keep track of an estimate for every single Q-Value.\n","<br><br>\n","<center>\n","<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2019/04/Screenshot-2019-04-16-at-5.46.01-PM-670x440.png\" width=650px />\n","</center>\n","<br><br>\n","\n","The solution is to find a function $Q_θ(s, a)$ that approximates the Q-Value of any state-action pair (s, a) using a manageable number of parameters (given by the parameter vector θ). This is called **Approximate Q-Learning**.\n","\n","$$Q_{target}(s, a) = r + \\gamma\\ maxQ_{\\theta}(s', a')$$\n","\n","For years it was recommended to use linear combinations of handcrafted features extracted from the state to estimate Q-Values, but in 2013, DeepMind showed that deep neural networks can work much better, especially for complex problems, and it does not require any feature engineering. A DNN used to estimate Q-Values is called a Deep Q-Network (DQN), and using a DQN for Approximate Q-Learning is called **Deep Q-Learning**.\n","\n","In deep Q-learning, we use a neural network to approximate the Q-value function. The state is given as the input and the Q-value of all possible actions is generated as the output."]},{"cell_type":"markdown","metadata":{"id":"jr2ZG0TQHAOT"},"source":["### Implementing Deep Q-Learning for Atari Ms-Pacman"]},{"cell_type":"markdown","metadata":{"id":"Aze2K918HAOU"},"source":["#### **Atari Ms-Pacman**\n","\n","<center>\n","<img src=\"https://cdn.iisc.talentsprint.com/AIAS/Pacman.png\" width=450px height=350px/>\n","</center>\n","<br><br>\n","\n","In this environment, a player controls the Pacman, who attempts to collect all of the pellets while avoiding ghosts that pursue him. The agent must learn to control the Pacman by moving left, right, up, and down, collecting all the pellets without being caught by any of the ghosts.\n","\n","Let's see the details of different aspects, such as rewards, states, and actions, that needs to be considered while modeling an RL solution for this problem.\n"]},{"cell_type":"markdown","source":["#### **Actions:**\n","\n","There are 9 discrete deterministic actions:\n","\n","- 0: NOOP (no operation)\n","- 1: UP\n","- 2: RIGHT\n","- 3: LEFT\n","- 4: DOWN\n","- 5: UPRIGHT\n","- 6: UPLEFT\n","- 7: DOWNRIGHT\n","- 8: DOWNLEFT"],"metadata":{"id":"NiMjzWBi_wA7"}},{"cell_type":"markdown","source":["#### **States**\n","\n","By default, the environment returns the RGB image, of shape (210, 160, 3), that is displayed to human players as an observation."],"metadata":{"id":"c2NF85cgdt8V"}},{"cell_type":"markdown","source":["#### **Rewards**\n","\n","Points are obtained by eating pellets, while avoiding ghosts (contact with one causes Ms. Pac-Man to lose a life). Eating one of the special power pellets turns the ghosts blue for a small duration, allowing them to be eaten for extra points."],"metadata":{"id":"axEMknOpgm0Q"}},{"cell_type":"markdown","source":["To know more about Ms. Pacman environment, refer [here](https://www.gymlibrary.dev/environments/atari/ms_pacman/)."],"metadata":{"id":"e-A9etVMCSMB"}},{"cell_type":"markdown","source":["### Install dependencies"],"metadata":{"id":"82enRIqx2pWz"}},{"cell_type":"code","source":["!pip3 -q install PyVirtualDisplay\n","!sudo apt-get install xvfb\n","!sudo apt-get install python-opengl\n","!sudo apt-get install ffmpeg\n","!pip -q install gym-notebook-wrapper\n","!pip -q install gym[atari]\n","!pip -q install gym[accept-rom-license]\n","!pip -q install pyglet\n","!sudo apt install freeglut3-dev freeglut3 libgl1-mesa-dev libglu1-mesa-dev libxext-dev libxt-dev\n","!sudo apt install python3-opengl libgl1-mesa-glx libglu1-mesa"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V8ZPjGStgGUC","outputId":"88433638-fb6f-4e55-c088-947cc1f06a3f","executionInfo":{"status":"ok","timestamp":1720235320910,"user_tz":-330,"elapsed":74359,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n","  xfonts-utils xserver-common\n","The following NEW packages will be installed:\n","  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n","  xfonts-utils xserver-common xvfb\n","0 upgraded, 9 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 7,813 kB of archives.\n","After this operation, 11.9 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.10 [28.5 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.10 [863 kB]\n","Fetched 7,813 kB in 2s (3,661 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 9.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libfontenc1:amd64.\n","(Reading database ... 121925 files and directories currently installed.)\n","Preparing to unpack .../0-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n","Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Selecting previously unselected package libxfont2:amd64.\n","Preparing to unpack .../1-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n","Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n","Selecting previously unselected package libxkbfile1:amd64.\n","Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n","Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Selecting previously unselected package x11-xkb-utils.\n","Preparing to unpack .../3-x11-xkb-utils_7.7+5build4_amd64.deb ...\n","Unpacking x11-xkb-utils (7.7+5build4) ...\n","Selecting previously unselected package xfonts-encodings.\n","Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n","Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n","Selecting previously unselected package xfonts-utils.\n","Preparing to unpack .../5-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n","Unpacking xfonts-utils (1:7.7+6build2) ...\n","Selecting previously unselected package xfonts-base.\n","Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n","Unpacking xfonts-base (1:1.0.5) ...\n","Selecting previously unselected package xserver-common.\n","Preparing to unpack .../7-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.10_all.deb ...\n","Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n","Selecting previously unselected package xvfb.\n","Preparing to unpack .../8-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.10_amd64.deb ...\n","Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n","Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n","Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n","Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n","Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n","Setting up x11-xkb-utils (7.7+5build4) ...\n","Setting up xfonts-utils (1:7.7+6build2) ...\n","Setting up xfonts-base (1:1.0.5) ...\n","Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.10) ...\n","Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.10) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","E: Unable to locate package python-opengl\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.7/434.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m884.3/884.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libxext-dev is already the newest version (2:1.3.4-1build1).\n","libxext-dev set to manually installed.\n","The following additional packages will be installed:\n","  libegl-dev libgl-dev libgles-dev libgles1 libglu1-mesa libglvnd-core-dev\n","  libglvnd-dev libglx-dev libice-dev libopengl-dev libsm-dev\n","Suggested packages:\n","  libice-doc libsm-doc libxt-doc\n","The following NEW packages will be installed:\n","  freeglut3 freeglut3-dev libegl-dev libgl-dev libgl1-mesa-dev libgles-dev\n","  libgles1 libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev\n","  libglx-dev libice-dev libopengl-dev libsm-dev libxt-dev\n","0 upgraded, 16 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 1,262 kB of archives.\n","After this operation, 6,754 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n","Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n","Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.2.1-1ubuntu3.1~22.04.2 [6,842 B]\n","Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n","Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n","Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n","Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3-dev amd64 2.8.1-6 [126 kB]\n","Fetched 1,262 kB in 2s (539 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 16.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package freeglut3:amd64.\n","(Reading database ... 122488 files and directories currently installed.)\n","Preparing to unpack .../00-freeglut3_2.8.1-6_amd64.deb ...\n","Unpacking freeglut3:amd64 (2.8.1-6) ...\n","Selecting previously unselected package libglx-dev:amd64.\n","Preparing to unpack .../01-libglx-dev_1.4.0-1_amd64.deb ...\n","Unpacking libglx-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libgl-dev:amd64.\n","Preparing to unpack .../02-libgl-dev_1.4.0-1_amd64.deb ...\n","Unpacking libgl-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libglvnd-core-dev:amd64.\n","Preparing to unpack .../03-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n","Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libegl-dev:amd64.\n","Preparing to unpack .../04-libegl-dev_1.4.0-1_amd64.deb ...\n","Unpacking libegl-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libgles1:amd64.\n","Preparing to unpack .../05-libgles1_1.4.0-1_amd64.deb ...\n","Unpacking libgles1:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libgles-dev:amd64.\n","Preparing to unpack .../06-libgles-dev_1.4.0-1_amd64.deb ...\n","Unpacking libgles-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libopengl-dev:amd64.\n","Preparing to unpack .../07-libopengl-dev_1.4.0-1_amd64.deb ...\n","Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libglvnd-dev:amd64.\n","Preparing to unpack .../08-libglvnd-dev_1.4.0-1_amd64.deb ...\n","Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n","Selecting previously unselected package libgl1-mesa-dev:amd64.\n","Preparing to unpack .../09-libgl1-mesa-dev_23.2.1-1ubuntu3.1~22.04.2_amd64.deb ...\n","Unpacking libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n","Selecting previously unselected package libglu1-mesa:amd64.\n","Preparing to unpack .../10-libglu1-mesa_9.0.2-1_amd64.deb ...\n","Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n","Selecting previously unselected package libglu1-mesa-dev:amd64.\n","Preparing to unpack .../11-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n","Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n","Selecting previously unselected package libice-dev:amd64.\n","Preparing to unpack .../12-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n","Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n","Selecting previously unselected package libsm-dev:amd64.\n","Preparing to unpack .../13-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n","Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n","Selecting previously unselected package libxt-dev:amd64.\n","Preparing to unpack .../14-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n","Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n","Selecting previously unselected package freeglut3-dev:amd64.\n","Preparing to unpack .../15-freeglut3-dev_2.8.1-6_amd64.deb ...\n","Unpacking freeglut3-dev:amd64 (2.8.1-6) ...\n","Setting up freeglut3:amd64 (2.8.1-6) ...\n","Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n","Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n","Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n","Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n","Setting up libgles1:amd64 (1.4.0-1) ...\n","Setting up libglx-dev:amd64 (1.4.0-1) ...\n","Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n","Setting up libopengl-dev:amd64 (1.4.0-1) ...\n","Setting up libgl-dev:amd64 (1.4.0-1) ...\n","Setting up libegl-dev:amd64 (1.4.0-1) ...\n","Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n","Setting up libgles-dev:amd64 (1.4.0-1) ...\n","Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n","Setting up libgl1-mesa-dev:amd64 (23.2.1-1ubuntu3.1~22.04.2) ...\n","Setting up freeglut3-dev:amd64 (2.8.1-6) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libglu1-mesa is already the newest version (9.0.2-1).\n","libglu1-mesa set to manually installed.\n","Suggested packages:\n","  libgle3 python3-numpy\n","The following NEW packages will be installed:\n","  libgl1-mesa-glx python3-opengl\n","0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 611 kB of archives.\n","After this operation, 7,470 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgl1-mesa-glx amd64 23.0.4-0ubuntu1~22.04.1 [5,584 B]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 python3-opengl all 3.1.5+dfsg-1 [605 kB]\n","Fetched 611 kB in 2s (341 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 2.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libgl1-mesa-glx:amd64.\n","(Reading database ... 122946 files and directories currently installed.)\n","Preparing to unpack .../libgl1-mesa-glx_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n","Unpacking libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n","Selecting previously unselected package python3-opengl.\n","Preparing to unpack .../python3-opengl_3.1.5+dfsg-1_all.deb ...\n","Unpacking python3-opengl (3.1.5+dfsg-1) ...\n","Setting up python3-opengl (3.1.5+dfsg-1) ...\n","Setting up libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n"]}]},{"cell_type":"markdown","metadata":{"id":"baUfsWTmHAOV"},"source":["### Import required packages"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"fA3knP9nHAOW","executionInfo":{"status":"ok","timestamp":1720235521515,"user_tz":-330,"elapsed":5798,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"outputs":[],"source":["import numpy as np\n","import gym\n","import gnwrapper\n","import glob\n","import io\n","import base64\n","from IPython.display import HTML\n","from pyvirtualdisplay import Display\n","from IPython import display as ipythondisplay\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import urllib.request\n","from IPython.display import clear_output\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"J_IiZIFaHAOX","colab":{"base_uri":"https://localhost:8080/"},"outputId":"58f6cb70-08ee-4828-fcd3-3e92bb61635e","executionInfo":{"status":"ok","timestamp":1720235526595,"user_tz":-330,"elapsed":1095,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["dict_values([EnvSpec(id='ALE/Tetris-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tetris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tetris', version=5), EnvSpec(id='ALE/Tetris-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tetris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tetris-ram', version=5), EnvSpec(id='ALE/Galaxian-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'galaxian', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Galaxian', version=5), EnvSpec(id='ALE/Galaxian-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'galaxian', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Galaxian-ram', version=5), EnvSpec(id='ALE/FishingDerby-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='FishingDerby', version=5), EnvSpec(id='ALE/FishingDerby-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='FishingDerby-ram', version=5), EnvSpec(id='ALE/Freeway-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Freeway', version=5), EnvSpec(id='ALE/Freeway-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Freeway-ram', version=5), EnvSpec(id='ALE/Venture-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Venture', version=5), EnvSpec(id='ALE/Venture-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Venture-ram', version=5), EnvSpec(id='ALE/Carnival-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Carnival', version=5), EnvSpec(id='ALE/Carnival-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Carnival-ram', version=5), EnvSpec(id='ALE/SpaceInvaders-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='SpaceInvaders', version=5), EnvSpec(id='ALE/SpaceInvaders-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='SpaceInvaders-ram', version=5), EnvSpec(id='ALE/Alien-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Alien', version=5), EnvSpec(id='ALE/Alien-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Alien-ram', version=5), EnvSpec(id='ALE/Tennis-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tennis', version=5), EnvSpec(id='ALE/Tennis-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tennis-ram', version=5), EnvSpec(id='ALE/BasicMath-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'basic_math', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BasicMath', version=5), EnvSpec(id='ALE/BasicMath-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'basic_math', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BasicMath-ram', version=5), EnvSpec(id='ALE/SirLancelot-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'sir_lancelot', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='SirLancelot', version=5), EnvSpec(id='ALE/SirLancelot-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'sir_lancelot', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='SirLancelot-ram', version=5), EnvSpec(id='ALE/PrivateEye-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='PrivateEye', version=5), EnvSpec(id='ALE/PrivateEye-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='PrivateEye-ram', version=5), EnvSpec(id='ALE/Zaxxon-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Zaxxon', version=5), EnvSpec(id='ALE/Zaxxon-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Zaxxon-ram', version=5), EnvSpec(id='ALE/Pitfall-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pitfall', version=5), EnvSpec(id='ALE/Pitfall-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pitfall-ram', version=5), EnvSpec(id='ALE/Turmoil-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'turmoil', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Turmoil', version=5), EnvSpec(id='ALE/Turmoil-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'turmoil', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Turmoil-ram', version=5), EnvSpec(id='ALE/Boxing-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Boxing', version=5), EnvSpec(id='ALE/Boxing-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Boxing-ram', version=5), EnvSpec(id='ALE/LaserGates-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'laser_gates', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='LaserGates', version=5), EnvSpec(id='ALE/LaserGates-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'laser_gates', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='LaserGates-ram', version=5), EnvSpec(id='ALE/Bowling-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Bowling', version=5), EnvSpec(id='ALE/Bowling-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Bowling-ram', version=5), EnvSpec(id='ALE/BeamRider-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BeamRider', version=5), EnvSpec(id='ALE/BeamRider-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BeamRider-ram', version=5), EnvSpec(id='ALE/DemonAttack-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='DemonAttack', version=5), EnvSpec(id='ALE/DemonAttack-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='DemonAttack-ram', version=5), EnvSpec(id='ALE/Jamesbond-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Jamesbond', version=5), EnvSpec(id='ALE/Jamesbond-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Jamesbond-ram', version=5), EnvSpec(id='ALE/Tutankham-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tutankham', version=5), EnvSpec(id='ALE/Tutankham-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Tutankham-ram', version=5), EnvSpec(id='ALE/Trondead-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'trondead', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Trondead', version=5), EnvSpec(id='ALE/Trondead-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'trondead', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Trondead-ram', version=5), EnvSpec(id='ALE/Backgammon-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'backgammon', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Backgammon', version=5), EnvSpec(id='ALE/Backgammon-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'backgammon', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Backgammon-ram', version=5), EnvSpec(id='ALE/Et-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'et', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Et', version=5), EnvSpec(id='ALE/Et-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'et', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Et-ram', version=5), EnvSpec(id='ALE/Adventure-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Adventure', version=5), EnvSpec(id='ALE/Adventure-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Adventure-ram', version=5), EnvSpec(id='ALE/MarioBros-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'mario_bros', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MarioBros', version=5), EnvSpec(id='ALE/MarioBros-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'mario_bros', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MarioBros-ram', version=5), EnvSpec(id='ALE/Atlantis2-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis2', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Atlantis2', version=5), EnvSpec(id='ALE/Atlantis2-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis2', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Atlantis2-ram', version=5), EnvSpec(id='ALE/Asterix-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Asterix', version=5), EnvSpec(id='ALE/Asterix-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Asterix-ram', version=5), EnvSpec(id='ALE/RoadRunner-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='RoadRunner', version=5), EnvSpec(id='ALE/RoadRunner-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='RoadRunner-ram', version=5), EnvSpec(id='ALE/AirRaid-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='AirRaid', version=5), EnvSpec(id='ALE/AirRaid-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='AirRaid-ram', version=5), EnvSpec(id='ALE/Casino-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'casino', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Casino', version=5), EnvSpec(id='ALE/Casino-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'casino', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Casino-ram', version=5), EnvSpec(id='ALE/Darkchambers-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'darkchambers', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Darkchambers', version=5), EnvSpec(id='ALE/Darkchambers-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'darkchambers', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Darkchambers-ram', version=5), EnvSpec(id='ALE/NameThisGame-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='NameThisGame', version=5), EnvSpec(id='ALE/NameThisGame-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='NameThisGame-ram', version=5), EnvSpec(id='ALE/LostLuggage-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'lost_luggage', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='LostLuggage', version=5), EnvSpec(id='ALE/LostLuggage-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'lost_luggage', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='LostLuggage-ram', version=5), EnvSpec(id='ALE/ChopperCommand-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='ChopperCommand', version=5), EnvSpec(id='ALE/ChopperCommand-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='ChopperCommand-ram', version=5), EnvSpec(id='ALE/Entombed-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'entombed', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Entombed', version=5), EnvSpec(id='ALE/Entombed-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'entombed', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Entombed-ram', version=5), EnvSpec(id='ALE/HumanCannonball-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'human_cannonball', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='HumanCannonball', version=5), EnvSpec(id='ALE/HumanCannonball-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'human_cannonball', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='HumanCannonball-ram', version=5), EnvSpec(id='ALE/Superman-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'superman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Superman', version=5), EnvSpec(id='ALE/Superman-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'superman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Superman-ram', version=5), EnvSpec(id='ALE/BattleZone-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BattleZone', version=5), EnvSpec(id='ALE/BattleZone-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BattleZone-ram', version=5), EnvSpec(id='ALE/SpaceWar-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_war', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='SpaceWar', version=5), EnvSpec(id='ALE/SpaceWar-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_war', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='SpaceWar-ram', version=5), EnvSpec(id='ALE/Blackjack-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'blackjack', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Blackjack', version=5), EnvSpec(id='ALE/Blackjack-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'blackjack', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Blackjack-ram', version=5), EnvSpec(id='ALE/StarGunner-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='StarGunner', version=5), EnvSpec(id='ALE/StarGunner-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='StarGunner-ram', version=5), EnvSpec(id='ALE/DoubleDunk-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='DoubleDunk', version=5), EnvSpec(id='ALE/DoubleDunk-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='DoubleDunk-ram', version=5), EnvSpec(id='ALE/JourneyEscape-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='JourneyEscape', version=5), EnvSpec(id='ALE/JourneyEscape-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='JourneyEscape-ram', version=5), EnvSpec(id='ALE/Asteroids-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Asteroids', version=5), EnvSpec(id='ALE/Asteroids-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Asteroids-ram', version=5), EnvSpec(id='ALE/Riverraid-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Riverraid', version=5), EnvSpec(id='ALE/Riverraid-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Riverraid-ram', version=5), EnvSpec(id='ALE/Robotank-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Robotank', version=5), EnvSpec(id='ALE/Robotank-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Robotank-ram', version=5), EnvSpec(id='ALE/Berzerk-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Berzerk', version=5), EnvSpec(id='ALE/Berzerk-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Berzerk-ram', version=5), EnvSpec(id='ALE/UpNDown-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='UpNDown', version=5), EnvSpec(id='ALE/UpNDown-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='UpNDown-ram', version=5), EnvSpec(id='ALE/MontezumaRevenge-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MontezumaRevenge', version=5), EnvSpec(id='ALE/MontezumaRevenge-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MontezumaRevenge-ram', version=5), EnvSpec(id='ALE/Hero-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Hero', version=5), EnvSpec(id='ALE/Hero-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Hero-ram', version=5), EnvSpec(id='ALE/Gopher-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Gopher', version=5), EnvSpec(id='ALE/Gopher-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Gopher-ram', version=5), EnvSpec(id='ALE/Hangman-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hangman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Hangman', version=5), EnvSpec(id='ALE/Hangman-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hangman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Hangman-ram', version=5), EnvSpec(id='ALE/BankHeist-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BankHeist', version=5), EnvSpec(id='ALE/BankHeist-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='BankHeist-ram', version=5), EnvSpec(id='ALE/KungFuMaster-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='KungFuMaster', version=5), EnvSpec(id='ALE/KungFuMaster-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='KungFuMaster-ram', version=5), EnvSpec(id='ALE/CrazyClimber-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='CrazyClimber', version=5), EnvSpec(id='ALE/CrazyClimber-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='CrazyClimber-ram', version=5), EnvSpec(id='ALE/Othello-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'othello', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Othello', version=5), EnvSpec(id='ALE/Othello-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'othello', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Othello-ram', version=5), EnvSpec(id='ALE/Solaris-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Solaris', version=5), EnvSpec(id='ALE/Solaris-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Solaris-ram', version=5), EnvSpec(id='ALE/Breakout-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Breakout', version=5), EnvSpec(id='ALE/Breakout-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Breakout-ram', version=5), EnvSpec(id='ALE/WizardOfWor-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='WizardOfWor', version=5), EnvSpec(id='ALE/WizardOfWor-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='WizardOfWor-ram', version=5), EnvSpec(id='ALE/ElevatorAction-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='ElevatorAction', version=5), EnvSpec(id='ALE/ElevatorAction-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='ElevatorAction-ram', version=5), EnvSpec(id='ALE/Centipede-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Centipede', version=5), EnvSpec(id='ALE/Centipede-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Centipede-ram', version=5), EnvSpec(id='ALE/FlagCapture-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'flag_capture', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='FlagCapture', version=5), EnvSpec(id='ALE/FlagCapture-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'flag_capture', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='FlagCapture-ram', version=5), EnvSpec(id='ALE/MsPacman-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MsPacman', version=5), EnvSpec(id='ALE/MsPacman-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MsPacman-ram', version=5), EnvSpec(id='ALE/YarsRevenge-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='YarsRevenge', version=5), EnvSpec(id='ALE/YarsRevenge-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='YarsRevenge-ram', version=5), EnvSpec(id='ALE/Krull-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Krull', version=5), EnvSpec(id='ALE/Krull-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Krull-ram', version=5), EnvSpec(id='ALE/Defender-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Defender', version=5), EnvSpec(id='ALE/Defender-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Defender-ram', version=5), EnvSpec(id='ALE/VideoCheckers-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_checkers', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='VideoCheckers', version=5), EnvSpec(id='ALE/VideoCheckers-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_checkers', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='VideoCheckers-ram', version=5), EnvSpec(id='ALE/Kangaroo-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Kangaroo', version=5), EnvSpec(id='ALE/Kangaroo-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Kangaroo-ram', version=5), EnvSpec(id='ALE/KeystoneKapers-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'keystone_kapers', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='KeystoneKapers', version=5), EnvSpec(id='ALE/KeystoneKapers-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'keystone_kapers', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='KeystoneKapers-ram', version=5), EnvSpec(id='ALE/Earthworld-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'earthworld', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Earthworld', version=5), EnvSpec(id='ALE/Earthworld-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'earthworld', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Earthworld-ram', version=5), EnvSpec(id='ALE/MiniatureGolf-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'miniature_golf', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MiniatureGolf', version=5), EnvSpec(id='ALE/MiniatureGolf-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'miniature_golf', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MiniatureGolf-ram', version=5), EnvSpec(id='ALE/KingKong-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'king_kong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='KingKong', version=5), EnvSpec(id='ALE/KingKong-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'king_kong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='KingKong-ram', version=5), EnvSpec(id='ALE/TicTacToe3D-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tic_tac_toe3_d', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='TicTacToe3D', version=5), EnvSpec(id='ALE/TicTacToe3D-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tic_tac_toe3_d', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='TicTacToe3D-ram', version=5), EnvSpec(id='ALE/Pitfall2-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall2', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pitfall2', version=5), EnvSpec(id='ALE/Pitfall2-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall2', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pitfall2-ram', version=5), EnvSpec(id='ALE/Amidar-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Amidar', version=5), EnvSpec(id='ALE/Amidar-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Amidar-ram', version=5), EnvSpec(id='ALE/WordZapper-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'word_zapper', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='WordZapper', version=5), EnvSpec(id='ALE/WordZapper-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'word_zapper', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='WordZapper-ram', version=5), EnvSpec(id='ALE/Skiing-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Skiing', version=5), EnvSpec(id='ALE/Skiing-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Skiing-ram', version=5), EnvSpec(id='ALE/Pooyan-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pooyan', version=5), EnvSpec(id='ALE/Pooyan-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pooyan-ram', version=5), EnvSpec(id='ALE/Gravitar-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Gravitar', version=5), EnvSpec(id='ALE/Gravitar-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Gravitar-ram', version=5), EnvSpec(id='ALE/Koolaid-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'koolaid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Koolaid', version=5), EnvSpec(id='ALE/Koolaid-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'koolaid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Koolaid-ram', version=5), EnvSpec(id='ALE/MrDo-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'mr_do', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MrDo', version=5), EnvSpec(id='ALE/MrDo-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'mr_do', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='MrDo-ram', version=5), EnvSpec(id='ALE/Kaboom-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kaboom', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Kaboom', version=5), EnvSpec(id='ALE/Kaboom-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kaboom', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Kaboom-ram', version=5), EnvSpec(id='ALE/TimePilot-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='TimePilot', version=5), EnvSpec(id='ALE/TimePilot-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='TimePilot-ram', version=5), EnvSpec(id='ALE/HauntedHouse-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'haunted_house', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='HauntedHouse', version=5), EnvSpec(id='ALE/HauntedHouse-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'haunted_house', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='HauntedHouse-ram', version=5), EnvSpec(id='ALE/VideoPinball-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='VideoPinball', version=5), EnvSpec(id='ALE/VideoPinball-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='VideoPinball-ram', version=5), EnvSpec(id='ALE/Atlantis-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Atlantis', version=5), EnvSpec(id='ALE/Atlantis-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Atlantis-ram', version=5), EnvSpec(id='ALE/Crossbow-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crossbow', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Crossbow', version=5), EnvSpec(id='ALE/Crossbow-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crossbow', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Crossbow-ram', version=5), EnvSpec(id='ALE/Enduro-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Enduro', version=5), EnvSpec(id='ALE/Enduro-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Enduro-ram', version=5), EnvSpec(id='ALE/Assault-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Assault', version=5), EnvSpec(id='ALE/Assault-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Assault-ram', version=5), EnvSpec(id='ALE/Phoenix-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Phoenix', version=5), EnvSpec(id='ALE/Phoenix-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Phoenix-ram', version=5), EnvSpec(id='ALE/Qbert-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Qbert', version=5), EnvSpec(id='ALE/Qbert-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Qbert-ram', version=5), EnvSpec(id='ALE/IceHockey-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='IceHockey', version=5), EnvSpec(id='ALE/IceHockey-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='IceHockey-ram', version=5), EnvSpec(id='ALE/Seaquest-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Seaquest', version=5), EnvSpec(id='ALE/Seaquest-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Seaquest-ram', version=5), EnvSpec(id='ALE/DonkeyKong-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'donkey_kong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='DonkeyKong', version=5), EnvSpec(id='ALE/DonkeyKong-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'donkey_kong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='DonkeyKong-ram', version=5), EnvSpec(id='ALE/Pong-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pong', version=5), EnvSpec(id='ALE/Pong-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pong-ram', version=5), EnvSpec(id='ALE/Frostbite-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Frostbite', version=5), EnvSpec(id='ALE/Frostbite-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Frostbite-ram', version=5), EnvSpec(id='ALE/Videocube-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'videocube', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Videocube', version=5), EnvSpec(id='ALE/Videocube-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'videocube', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Videocube-ram', version=5), EnvSpec(id='ALE/Videochess-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'videochess', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Videochess', version=5), EnvSpec(id='ALE/Videochess-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'videochess', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Videochess-ram', version=5), EnvSpec(id='ALE/Surround-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'surround', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Surround', version=5), EnvSpec(id='ALE/Surround-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'surround', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Surround-ram', version=5), EnvSpec(id='ALE/Klax-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'klax', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Klax', version=5), EnvSpec(id='ALE/Klax-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'klax', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Klax-ram', version=5), EnvSpec(id='ALE/Frogger-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frogger', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Frogger', version=5), EnvSpec(id='ALE/Frogger-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frogger', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Frogger-ram', version=5), EnvSpec(id='ALE/Pacman-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pacman', version=5), EnvSpec(id='ALE/Pacman-ram-v5', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=27000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace='ALE', name='Pacman-ram', version=5), EnvSpec(id='Adventure-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Adventure', version=0), EnvSpec(id='AdventureDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AdventureDeterministic', version=0), EnvSpec(id='AdventureNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AdventureNoFrameskip', version=0), EnvSpec(id='Adventure-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Adventure', version=4), EnvSpec(id='AdventureDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AdventureDeterministic', version=4), EnvSpec(id='AdventureNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AdventureNoFrameskip', version=4), EnvSpec(id='Adventure-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Adventure-ram', version=0), EnvSpec(id='Adventure-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Adventure-ramDeterministic', version=0), EnvSpec(id='Adventure-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Adventure-ramNoFrameskip', version=0), EnvSpec(id='Adventure-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Adventure-ram', version=4), EnvSpec(id='Adventure-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Adventure-ramDeterministic', version=4), EnvSpec(id='Adventure-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'adventure', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Adventure-ramNoFrameskip', version=4), EnvSpec(id='AirRaid-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='AirRaid', version=0), EnvSpec(id='AirRaidDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AirRaidDeterministic', version=0), EnvSpec(id='AirRaidNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AirRaidNoFrameskip', version=0), EnvSpec(id='AirRaid-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='AirRaid', version=4), EnvSpec(id='AirRaidDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AirRaidDeterministic', version=4), EnvSpec(id='AirRaidNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AirRaidNoFrameskip', version=4), EnvSpec(id='AirRaid-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='AirRaid-ram', version=0), EnvSpec(id='AirRaid-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AirRaid-ramDeterministic', version=0), EnvSpec(id='AirRaid-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AirRaid-ramNoFrameskip', version=0), EnvSpec(id='AirRaid-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='AirRaid-ram', version=4), EnvSpec(id='AirRaid-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AirRaid-ramDeterministic', version=4), EnvSpec(id='AirRaid-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'air_raid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AirRaid-ramNoFrameskip', version=4), EnvSpec(id='Alien-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Alien', version=0), EnvSpec(id='AlienDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AlienDeterministic', version=0), EnvSpec(id='AlienNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AlienNoFrameskip', version=0), EnvSpec(id='Alien-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Alien', version=4), EnvSpec(id='AlienDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AlienDeterministic', version=4), EnvSpec(id='AlienNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AlienNoFrameskip', version=4), EnvSpec(id='Alien-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Alien-ram', version=0), EnvSpec(id='Alien-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Alien-ramDeterministic', version=0), EnvSpec(id='Alien-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Alien-ramNoFrameskip', version=0), EnvSpec(id='Alien-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Alien-ram', version=4), EnvSpec(id='Alien-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Alien-ramDeterministic', version=4), EnvSpec(id='Alien-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'alien', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Alien-ramNoFrameskip', version=4), EnvSpec(id='Amidar-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Amidar', version=0), EnvSpec(id='AmidarDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AmidarDeterministic', version=0), EnvSpec(id='AmidarNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AmidarNoFrameskip', version=0), EnvSpec(id='Amidar-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Amidar', version=4), EnvSpec(id='AmidarDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AmidarDeterministic', version=4), EnvSpec(id='AmidarNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AmidarNoFrameskip', version=4), EnvSpec(id='Amidar-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Amidar-ram', version=0), EnvSpec(id='Amidar-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Amidar-ramDeterministic', version=0), EnvSpec(id='Amidar-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Amidar-ramNoFrameskip', version=0), EnvSpec(id='Amidar-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Amidar-ram', version=4), EnvSpec(id='Amidar-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Amidar-ramDeterministic', version=4), EnvSpec(id='Amidar-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'amidar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Amidar-ramNoFrameskip', version=4), EnvSpec(id='Assault-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Assault', version=0), EnvSpec(id='AssaultDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AssaultDeterministic', version=0), EnvSpec(id='AssaultNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AssaultNoFrameskip', version=0), EnvSpec(id='Assault-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Assault', version=4), EnvSpec(id='AssaultDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AssaultDeterministic', version=4), EnvSpec(id='AssaultNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AssaultNoFrameskip', version=4), EnvSpec(id='Assault-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Assault-ram', version=0), EnvSpec(id='Assault-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Assault-ramDeterministic', version=0), EnvSpec(id='Assault-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Assault-ramNoFrameskip', version=0), EnvSpec(id='Assault-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Assault-ram', version=4), EnvSpec(id='Assault-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Assault-ramDeterministic', version=4), EnvSpec(id='Assault-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'assault', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Assault-ramNoFrameskip', version=4), EnvSpec(id='Asterix-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asterix', version=0), EnvSpec(id='AsterixDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AsterixDeterministic', version=0), EnvSpec(id='AsterixNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AsterixNoFrameskip', version=0), EnvSpec(id='Asterix-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asterix', version=4), EnvSpec(id='AsterixDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AsterixDeterministic', version=4), EnvSpec(id='AsterixNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AsterixNoFrameskip', version=4), EnvSpec(id='Asterix-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asterix-ram', version=0), EnvSpec(id='Asterix-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Asterix-ramDeterministic', version=0), EnvSpec(id='Asterix-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Asterix-ramNoFrameskip', version=0), EnvSpec(id='Asterix-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asterix-ram', version=4), EnvSpec(id='Asterix-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Asterix-ramDeterministic', version=4), EnvSpec(id='Asterix-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asterix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Asterix-ramNoFrameskip', version=4), EnvSpec(id='Asteroids-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asteroids', version=0), EnvSpec(id='AsteroidsDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AsteroidsDeterministic', version=0), EnvSpec(id='AsteroidsNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AsteroidsNoFrameskip', version=0), EnvSpec(id='Asteroids-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asteroids', version=4), EnvSpec(id='AsteroidsDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AsteroidsDeterministic', version=4), EnvSpec(id='AsteroidsNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AsteroidsNoFrameskip', version=4), EnvSpec(id='Asteroids-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asteroids-ram', version=0), EnvSpec(id='Asteroids-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Asteroids-ramDeterministic', version=0), EnvSpec(id='Asteroids-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Asteroids-ramNoFrameskip', version=0), EnvSpec(id='Asteroids-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Asteroids-ram', version=4), EnvSpec(id='Asteroids-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Asteroids-ramDeterministic', version=4), EnvSpec(id='Asteroids-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'asteroids', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Asteroids-ramNoFrameskip', version=4), EnvSpec(id='Atlantis-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Atlantis', version=0), EnvSpec(id='AtlantisDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AtlantisDeterministic', version=0), EnvSpec(id='AtlantisNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AtlantisNoFrameskip', version=0), EnvSpec(id='Atlantis-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Atlantis', version=4), EnvSpec(id='AtlantisDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='AtlantisDeterministic', version=4), EnvSpec(id='AtlantisNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='AtlantisNoFrameskip', version=4), EnvSpec(id='Atlantis-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Atlantis-ram', version=0), EnvSpec(id='Atlantis-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Atlantis-ramDeterministic', version=0), EnvSpec(id='Atlantis-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Atlantis-ramNoFrameskip', version=0), EnvSpec(id='Atlantis-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Atlantis-ram', version=4), EnvSpec(id='Atlantis-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Atlantis-ramDeterministic', version=4), EnvSpec(id='Atlantis-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'atlantis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Atlantis-ramNoFrameskip', version=4), EnvSpec(id='BankHeist-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BankHeist', version=0), EnvSpec(id='BankHeistDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BankHeistDeterministic', version=0), EnvSpec(id='BankHeistNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BankHeistNoFrameskip', version=0), EnvSpec(id='BankHeist-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BankHeist', version=4), EnvSpec(id='BankHeistDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BankHeistDeterministic', version=4), EnvSpec(id='BankHeistNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BankHeistNoFrameskip', version=4), EnvSpec(id='BankHeist-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BankHeist-ram', version=0), EnvSpec(id='BankHeist-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BankHeist-ramDeterministic', version=0), EnvSpec(id='BankHeist-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BankHeist-ramNoFrameskip', version=0), EnvSpec(id='BankHeist-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BankHeist-ram', version=4), EnvSpec(id='BankHeist-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BankHeist-ramDeterministic', version=4), EnvSpec(id='BankHeist-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bank_heist', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BankHeist-ramNoFrameskip', version=4), EnvSpec(id='BattleZone-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BattleZone', version=0), EnvSpec(id='BattleZoneDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BattleZoneDeterministic', version=0), EnvSpec(id='BattleZoneNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BattleZoneNoFrameskip', version=0), EnvSpec(id='BattleZone-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BattleZone', version=4), EnvSpec(id='BattleZoneDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BattleZoneDeterministic', version=4), EnvSpec(id='BattleZoneNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BattleZoneNoFrameskip', version=4), EnvSpec(id='BattleZone-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BattleZone-ram', version=0), EnvSpec(id='BattleZone-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BattleZone-ramDeterministic', version=0), EnvSpec(id='BattleZone-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BattleZone-ramNoFrameskip', version=0), EnvSpec(id='BattleZone-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BattleZone-ram', version=4), EnvSpec(id='BattleZone-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BattleZone-ramDeterministic', version=4), EnvSpec(id='BattleZone-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'battle_zone', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BattleZone-ramNoFrameskip', version=4), EnvSpec(id='BeamRider-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BeamRider', version=0), EnvSpec(id='BeamRiderDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BeamRiderDeterministic', version=0), EnvSpec(id='BeamRiderNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BeamRiderNoFrameskip', version=0), EnvSpec(id='BeamRider-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BeamRider', version=4), EnvSpec(id='BeamRiderDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BeamRiderDeterministic', version=4), EnvSpec(id='BeamRiderNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BeamRiderNoFrameskip', version=4), EnvSpec(id='BeamRider-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BeamRider-ram', version=0), EnvSpec(id='BeamRider-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BeamRider-ramDeterministic', version=0), EnvSpec(id='BeamRider-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BeamRider-ramNoFrameskip', version=0), EnvSpec(id='BeamRider-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='BeamRider-ram', version=4), EnvSpec(id='BeamRider-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BeamRider-ramDeterministic', version=4), EnvSpec(id='BeamRider-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'beam_rider', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BeamRider-ramNoFrameskip', version=4), EnvSpec(id='Berzerk-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Berzerk', version=0), EnvSpec(id='BerzerkDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BerzerkDeterministic', version=0), EnvSpec(id='BerzerkNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BerzerkNoFrameskip', version=0), EnvSpec(id='Berzerk-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Berzerk', version=4), EnvSpec(id='BerzerkDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BerzerkDeterministic', version=4), EnvSpec(id='BerzerkNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BerzerkNoFrameskip', version=4), EnvSpec(id='Berzerk-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Berzerk-ram', version=0), EnvSpec(id='Berzerk-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Berzerk-ramDeterministic', version=0), EnvSpec(id='Berzerk-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Berzerk-ramNoFrameskip', version=0), EnvSpec(id='Berzerk-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Berzerk-ram', version=4), EnvSpec(id='Berzerk-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Berzerk-ramDeterministic', version=4), EnvSpec(id='Berzerk-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'berzerk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Berzerk-ramNoFrameskip', version=4), EnvSpec(id='Bowling-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Bowling', version=0), EnvSpec(id='BowlingDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BowlingDeterministic', version=0), EnvSpec(id='BowlingNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BowlingNoFrameskip', version=0), EnvSpec(id='Bowling-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Bowling', version=4), EnvSpec(id='BowlingDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BowlingDeterministic', version=4), EnvSpec(id='BowlingNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BowlingNoFrameskip', version=4), EnvSpec(id='Bowling-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Bowling-ram', version=0), EnvSpec(id='Bowling-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Bowling-ramDeterministic', version=0), EnvSpec(id='Bowling-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Bowling-ramNoFrameskip', version=0), EnvSpec(id='Bowling-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Bowling-ram', version=4), EnvSpec(id='Bowling-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Bowling-ramDeterministic', version=4), EnvSpec(id='Bowling-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'bowling', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Bowling-ramNoFrameskip', version=4), EnvSpec(id='Boxing-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Boxing', version=0), EnvSpec(id='BoxingDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BoxingDeterministic', version=0), EnvSpec(id='BoxingNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BoxingNoFrameskip', version=0), EnvSpec(id='Boxing-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Boxing', version=4), EnvSpec(id='BoxingDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BoxingDeterministic', version=4), EnvSpec(id='BoxingNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BoxingNoFrameskip', version=4), EnvSpec(id='Boxing-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Boxing-ram', version=0), EnvSpec(id='Boxing-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Boxing-ramDeterministic', version=0), EnvSpec(id='Boxing-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Boxing-ramNoFrameskip', version=0), EnvSpec(id='Boxing-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Boxing-ram', version=4), EnvSpec(id='Boxing-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Boxing-ramDeterministic', version=4), EnvSpec(id='Boxing-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'boxing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Boxing-ramNoFrameskip', version=4), EnvSpec(id='Breakout-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Breakout', version=0), EnvSpec(id='BreakoutDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BreakoutDeterministic', version=0), EnvSpec(id='BreakoutNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BreakoutNoFrameskip', version=0), EnvSpec(id='Breakout-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Breakout', version=4), EnvSpec(id='BreakoutDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='BreakoutDeterministic', version=4), EnvSpec(id='BreakoutNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='BreakoutNoFrameskip', version=4), EnvSpec(id='Breakout-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Breakout-ram', version=0), EnvSpec(id='Breakout-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Breakout-ramDeterministic', version=0), EnvSpec(id='Breakout-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Breakout-ramNoFrameskip', version=0), EnvSpec(id='Breakout-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Breakout-ram', version=4), EnvSpec(id='Breakout-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Breakout-ramDeterministic', version=4), EnvSpec(id='Breakout-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'breakout', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Breakout-ramNoFrameskip', version=4), EnvSpec(id='Carnival-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Carnival', version=0), EnvSpec(id='CarnivalDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CarnivalDeterministic', version=0), EnvSpec(id='CarnivalNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CarnivalNoFrameskip', version=0), EnvSpec(id='Carnival-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Carnival', version=4), EnvSpec(id='CarnivalDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CarnivalDeterministic', version=4), EnvSpec(id='CarnivalNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CarnivalNoFrameskip', version=4), EnvSpec(id='Carnival-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Carnival-ram', version=0), EnvSpec(id='Carnival-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Carnival-ramDeterministic', version=0), EnvSpec(id='Carnival-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Carnival-ramNoFrameskip', version=0), EnvSpec(id='Carnival-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Carnival-ram', version=4), EnvSpec(id='Carnival-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Carnival-ramDeterministic', version=4), EnvSpec(id='Carnival-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'carnival', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Carnival-ramNoFrameskip', version=4), EnvSpec(id='Centipede-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Centipede', version=0), EnvSpec(id='CentipedeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CentipedeDeterministic', version=0), EnvSpec(id='CentipedeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CentipedeNoFrameskip', version=0), EnvSpec(id='Centipede-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Centipede', version=4), EnvSpec(id='CentipedeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CentipedeDeterministic', version=4), EnvSpec(id='CentipedeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CentipedeNoFrameskip', version=4), EnvSpec(id='Centipede-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Centipede-ram', version=0), EnvSpec(id='Centipede-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Centipede-ramDeterministic', version=0), EnvSpec(id='Centipede-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Centipede-ramNoFrameskip', version=0), EnvSpec(id='Centipede-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Centipede-ram', version=4), EnvSpec(id='Centipede-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Centipede-ramDeterministic', version=4), EnvSpec(id='Centipede-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'centipede', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Centipede-ramNoFrameskip', version=4), EnvSpec(id='ChopperCommand-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ChopperCommand', version=0), EnvSpec(id='ChopperCommandDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ChopperCommandDeterministic', version=0), EnvSpec(id='ChopperCommandNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ChopperCommandNoFrameskip', version=0), EnvSpec(id='ChopperCommand-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ChopperCommand', version=4), EnvSpec(id='ChopperCommandDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ChopperCommandDeterministic', version=4), EnvSpec(id='ChopperCommandNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ChopperCommandNoFrameskip', version=4), EnvSpec(id='ChopperCommand-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ChopperCommand-ram', version=0), EnvSpec(id='ChopperCommand-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ChopperCommand-ramDeterministic', version=0), EnvSpec(id='ChopperCommand-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ChopperCommand-ramNoFrameskip', version=0), EnvSpec(id='ChopperCommand-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ChopperCommand-ram', version=4), EnvSpec(id='ChopperCommand-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ChopperCommand-ramDeterministic', version=4), EnvSpec(id='ChopperCommand-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'chopper_command', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ChopperCommand-ramNoFrameskip', version=4), EnvSpec(id='CrazyClimber-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='CrazyClimber', version=0), EnvSpec(id='CrazyClimberDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CrazyClimberDeterministic', version=0), EnvSpec(id='CrazyClimberNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CrazyClimberNoFrameskip', version=0), EnvSpec(id='CrazyClimber-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='CrazyClimber', version=4), EnvSpec(id='CrazyClimberDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CrazyClimberDeterministic', version=4), EnvSpec(id='CrazyClimberNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CrazyClimberNoFrameskip', version=4), EnvSpec(id='CrazyClimber-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='CrazyClimber-ram', version=0), EnvSpec(id='CrazyClimber-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CrazyClimber-ramDeterministic', version=0), EnvSpec(id='CrazyClimber-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CrazyClimber-ramNoFrameskip', version=0), EnvSpec(id='CrazyClimber-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='CrazyClimber-ram', version=4), EnvSpec(id='CrazyClimber-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='CrazyClimber-ramDeterministic', version=4), EnvSpec(id='CrazyClimber-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'crazy_climber', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='CrazyClimber-ramNoFrameskip', version=4), EnvSpec(id='Defender-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Defender', version=0), EnvSpec(id='DefenderDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DefenderDeterministic', version=0), EnvSpec(id='DefenderNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DefenderNoFrameskip', version=0), EnvSpec(id='Defender-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Defender', version=4), EnvSpec(id='DefenderDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DefenderDeterministic', version=4), EnvSpec(id='DefenderNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DefenderNoFrameskip', version=4), EnvSpec(id='Defender-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Defender-ram', version=0), EnvSpec(id='Defender-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Defender-ramDeterministic', version=0), EnvSpec(id='Defender-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Defender-ramNoFrameskip', version=0), EnvSpec(id='Defender-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Defender-ram', version=4), EnvSpec(id='Defender-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Defender-ramDeterministic', version=4), EnvSpec(id='Defender-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'defender', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Defender-ramNoFrameskip', version=4), EnvSpec(id='DemonAttack-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DemonAttack', version=0), EnvSpec(id='DemonAttackDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DemonAttackDeterministic', version=0), EnvSpec(id='DemonAttackNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DemonAttackNoFrameskip', version=0), EnvSpec(id='DemonAttack-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DemonAttack', version=4), EnvSpec(id='DemonAttackDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DemonAttackDeterministic', version=4), EnvSpec(id='DemonAttackNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DemonAttackNoFrameskip', version=4), EnvSpec(id='DemonAttack-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DemonAttack-ram', version=0), EnvSpec(id='DemonAttack-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DemonAttack-ramDeterministic', version=0), EnvSpec(id='DemonAttack-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DemonAttack-ramNoFrameskip', version=0), EnvSpec(id='DemonAttack-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DemonAttack-ram', version=4), EnvSpec(id='DemonAttack-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DemonAttack-ramDeterministic', version=4), EnvSpec(id='DemonAttack-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'demon_attack', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DemonAttack-ramNoFrameskip', version=4), EnvSpec(id='DoubleDunk-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DoubleDunk', version=0), EnvSpec(id='DoubleDunkDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DoubleDunkDeterministic', version=0), EnvSpec(id='DoubleDunkNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DoubleDunkNoFrameskip', version=0), EnvSpec(id='DoubleDunk-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DoubleDunk', version=4), EnvSpec(id='DoubleDunkDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DoubleDunkDeterministic', version=4), EnvSpec(id='DoubleDunkNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DoubleDunkNoFrameskip', version=4), EnvSpec(id='DoubleDunk-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DoubleDunk-ram', version=0), EnvSpec(id='DoubleDunk-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DoubleDunk-ramDeterministic', version=0), EnvSpec(id='DoubleDunk-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DoubleDunk-ramNoFrameskip', version=0), EnvSpec(id='DoubleDunk-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='DoubleDunk-ram', version=4), EnvSpec(id='DoubleDunk-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='DoubleDunk-ramDeterministic', version=4), EnvSpec(id='DoubleDunk-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'double_dunk', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='DoubleDunk-ramNoFrameskip', version=4), EnvSpec(id='ElevatorAction-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ElevatorAction', version=0), EnvSpec(id='ElevatorActionDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ElevatorActionDeterministic', version=0), EnvSpec(id='ElevatorActionNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ElevatorActionNoFrameskip', version=0), EnvSpec(id='ElevatorAction-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ElevatorAction', version=4), EnvSpec(id='ElevatorActionDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ElevatorActionDeterministic', version=4), EnvSpec(id='ElevatorActionNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ElevatorActionNoFrameskip', version=4), EnvSpec(id='ElevatorAction-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ElevatorAction-ram', version=0), EnvSpec(id='ElevatorAction-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ElevatorAction-ramDeterministic', version=0), EnvSpec(id='ElevatorAction-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ElevatorAction-ramNoFrameskip', version=0), EnvSpec(id='ElevatorAction-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='ElevatorAction-ram', version=4), EnvSpec(id='ElevatorAction-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ElevatorAction-ramDeterministic', version=4), EnvSpec(id='ElevatorAction-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'elevator_action', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ElevatorAction-ramNoFrameskip', version=4), EnvSpec(id='Enduro-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Enduro', version=0), EnvSpec(id='EnduroDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='EnduroDeterministic', version=0), EnvSpec(id='EnduroNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='EnduroNoFrameskip', version=0), EnvSpec(id='Enduro-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Enduro', version=4), EnvSpec(id='EnduroDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='EnduroDeterministic', version=4), EnvSpec(id='EnduroNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='EnduroNoFrameskip', version=4), EnvSpec(id='Enduro-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Enduro-ram', version=0), EnvSpec(id='Enduro-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Enduro-ramDeterministic', version=0), EnvSpec(id='Enduro-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Enduro-ramNoFrameskip', version=0), EnvSpec(id='Enduro-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Enduro-ram', version=4), EnvSpec(id='Enduro-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Enduro-ramDeterministic', version=4), EnvSpec(id='Enduro-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'enduro', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Enduro-ramNoFrameskip', version=4), EnvSpec(id='FishingDerby-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='FishingDerby', version=0), EnvSpec(id='FishingDerbyDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FishingDerbyDeterministic', version=0), EnvSpec(id='FishingDerbyNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FishingDerbyNoFrameskip', version=0), EnvSpec(id='FishingDerby-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='FishingDerby', version=4), EnvSpec(id='FishingDerbyDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FishingDerbyDeterministic', version=4), EnvSpec(id='FishingDerbyNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FishingDerbyNoFrameskip', version=4), EnvSpec(id='FishingDerby-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='FishingDerby-ram', version=0), EnvSpec(id='FishingDerby-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FishingDerby-ramDeterministic', version=0), EnvSpec(id='FishingDerby-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FishingDerby-ramNoFrameskip', version=0), EnvSpec(id='FishingDerby-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='FishingDerby-ram', version=4), EnvSpec(id='FishingDerby-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FishingDerby-ramDeterministic', version=4), EnvSpec(id='FishingDerby-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'fishing_derby', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FishingDerby-ramNoFrameskip', version=4), EnvSpec(id='Freeway-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Freeway', version=0), EnvSpec(id='FreewayDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FreewayDeterministic', version=0), EnvSpec(id='FreewayNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FreewayNoFrameskip', version=0), EnvSpec(id='Freeway-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Freeway', version=4), EnvSpec(id='FreewayDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FreewayDeterministic', version=4), EnvSpec(id='FreewayNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FreewayNoFrameskip', version=4), EnvSpec(id='Freeway-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Freeway-ram', version=0), EnvSpec(id='Freeway-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Freeway-ramDeterministic', version=0), EnvSpec(id='Freeway-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Freeway-ramNoFrameskip', version=0), EnvSpec(id='Freeway-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Freeway-ram', version=4), EnvSpec(id='Freeway-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Freeway-ramDeterministic', version=4), EnvSpec(id='Freeway-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'freeway', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Freeway-ramNoFrameskip', version=4), EnvSpec(id='Frostbite-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Frostbite', version=0), EnvSpec(id='FrostbiteDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FrostbiteDeterministic', version=0), EnvSpec(id='FrostbiteNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FrostbiteNoFrameskip', version=0), EnvSpec(id='Frostbite-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Frostbite', version=4), EnvSpec(id='FrostbiteDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='FrostbiteDeterministic', version=4), EnvSpec(id='FrostbiteNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='FrostbiteNoFrameskip', version=4), EnvSpec(id='Frostbite-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Frostbite-ram', version=0), EnvSpec(id='Frostbite-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Frostbite-ramDeterministic', version=0), EnvSpec(id='Frostbite-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Frostbite-ramNoFrameskip', version=0), EnvSpec(id='Frostbite-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Frostbite-ram', version=4), EnvSpec(id='Frostbite-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Frostbite-ramDeterministic', version=4), EnvSpec(id='Frostbite-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'frostbite', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Frostbite-ramNoFrameskip', version=4), EnvSpec(id='Gopher-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gopher', version=0), EnvSpec(id='GopherDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='GopherDeterministic', version=0), EnvSpec(id='GopherNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='GopherNoFrameskip', version=0), EnvSpec(id='Gopher-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gopher', version=4), EnvSpec(id='GopherDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='GopherDeterministic', version=4), EnvSpec(id='GopherNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='GopherNoFrameskip', version=4), EnvSpec(id='Gopher-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gopher-ram', version=0), EnvSpec(id='Gopher-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Gopher-ramDeterministic', version=0), EnvSpec(id='Gopher-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Gopher-ramNoFrameskip', version=0), EnvSpec(id='Gopher-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gopher-ram', version=4), EnvSpec(id='Gopher-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Gopher-ramDeterministic', version=4), EnvSpec(id='Gopher-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gopher', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Gopher-ramNoFrameskip', version=4), EnvSpec(id='Gravitar-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gravitar', version=0), EnvSpec(id='GravitarDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='GravitarDeterministic', version=0), EnvSpec(id='GravitarNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='GravitarNoFrameskip', version=0), EnvSpec(id='Gravitar-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gravitar', version=4), EnvSpec(id='GravitarDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='GravitarDeterministic', version=4), EnvSpec(id='GravitarNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='GravitarNoFrameskip', version=4), EnvSpec(id='Gravitar-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gravitar-ram', version=0), EnvSpec(id='Gravitar-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Gravitar-ramDeterministic', version=0), EnvSpec(id='Gravitar-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Gravitar-ramNoFrameskip', version=0), EnvSpec(id='Gravitar-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Gravitar-ram', version=4), EnvSpec(id='Gravitar-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Gravitar-ramDeterministic', version=4), EnvSpec(id='Gravitar-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'gravitar', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Gravitar-ramNoFrameskip', version=4), EnvSpec(id='Hero-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Hero', version=0), EnvSpec(id='HeroDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='HeroDeterministic', version=0), EnvSpec(id='HeroNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='HeroNoFrameskip', version=0), EnvSpec(id='Hero-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Hero', version=4), EnvSpec(id='HeroDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='HeroDeterministic', version=4), EnvSpec(id='HeroNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='HeroNoFrameskip', version=4), EnvSpec(id='Hero-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Hero-ram', version=0), EnvSpec(id='Hero-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Hero-ramDeterministic', version=0), EnvSpec(id='Hero-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Hero-ramNoFrameskip', version=0), EnvSpec(id='Hero-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Hero-ram', version=4), EnvSpec(id='Hero-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Hero-ramDeterministic', version=4), EnvSpec(id='Hero-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'hero', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Hero-ramNoFrameskip', version=4), EnvSpec(id='IceHockey-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='IceHockey', version=0), EnvSpec(id='IceHockeyDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='IceHockeyDeterministic', version=0), EnvSpec(id='IceHockeyNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='IceHockeyNoFrameskip', version=0), EnvSpec(id='IceHockey-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='IceHockey', version=4), EnvSpec(id='IceHockeyDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='IceHockeyDeterministic', version=4), EnvSpec(id='IceHockeyNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='IceHockeyNoFrameskip', version=4), EnvSpec(id='IceHockey-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='IceHockey-ram', version=0), EnvSpec(id='IceHockey-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='IceHockey-ramDeterministic', version=0), EnvSpec(id='IceHockey-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='IceHockey-ramNoFrameskip', version=0), EnvSpec(id='IceHockey-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='IceHockey-ram', version=4), EnvSpec(id='IceHockey-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='IceHockey-ramDeterministic', version=4), EnvSpec(id='IceHockey-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ice_hockey', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='IceHockey-ramNoFrameskip', version=4), EnvSpec(id='Jamesbond-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Jamesbond', version=0), EnvSpec(id='JamesbondDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JamesbondDeterministic', version=0), EnvSpec(id='JamesbondNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JamesbondNoFrameskip', version=0), EnvSpec(id='Jamesbond-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Jamesbond', version=4), EnvSpec(id='JamesbondDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JamesbondDeterministic', version=4), EnvSpec(id='JamesbondNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JamesbondNoFrameskip', version=4), EnvSpec(id='Jamesbond-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Jamesbond-ram', version=0), EnvSpec(id='Jamesbond-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Jamesbond-ramDeterministic', version=0), EnvSpec(id='Jamesbond-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Jamesbond-ramNoFrameskip', version=0), EnvSpec(id='Jamesbond-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Jamesbond-ram', version=4), EnvSpec(id='Jamesbond-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Jamesbond-ramDeterministic', version=4), EnvSpec(id='Jamesbond-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'jamesbond', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Jamesbond-ramNoFrameskip', version=4), EnvSpec(id='JourneyEscape-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='JourneyEscape', version=0), EnvSpec(id='JourneyEscapeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JourneyEscapeDeterministic', version=0), EnvSpec(id='JourneyEscapeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JourneyEscapeNoFrameskip', version=0), EnvSpec(id='JourneyEscape-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='JourneyEscape', version=4), EnvSpec(id='JourneyEscapeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JourneyEscapeDeterministic', version=4), EnvSpec(id='JourneyEscapeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JourneyEscapeNoFrameskip', version=4), EnvSpec(id='JourneyEscape-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='JourneyEscape-ram', version=0), EnvSpec(id='JourneyEscape-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JourneyEscape-ramDeterministic', version=0), EnvSpec(id='JourneyEscape-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JourneyEscape-ramNoFrameskip', version=0), EnvSpec(id='JourneyEscape-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='JourneyEscape-ram', version=4), EnvSpec(id='JourneyEscape-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='JourneyEscape-ramDeterministic', version=4), EnvSpec(id='JourneyEscape-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'journey_escape', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='JourneyEscape-ramNoFrameskip', version=4), EnvSpec(id='Kangaroo-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Kangaroo', version=0), EnvSpec(id='KangarooDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KangarooDeterministic', version=0), EnvSpec(id='KangarooNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KangarooNoFrameskip', version=0), EnvSpec(id='Kangaroo-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Kangaroo', version=4), EnvSpec(id='KangarooDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KangarooDeterministic', version=4), EnvSpec(id='KangarooNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KangarooNoFrameskip', version=4), EnvSpec(id='Kangaroo-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Kangaroo-ram', version=0), EnvSpec(id='Kangaroo-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Kangaroo-ramDeterministic', version=0), EnvSpec(id='Kangaroo-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Kangaroo-ramNoFrameskip', version=0), EnvSpec(id='Kangaroo-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Kangaroo-ram', version=4), EnvSpec(id='Kangaroo-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Kangaroo-ramDeterministic', version=4), EnvSpec(id='Kangaroo-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kangaroo', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Kangaroo-ramNoFrameskip', version=4), EnvSpec(id='Krull-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Krull', version=0), EnvSpec(id='KrullDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KrullDeterministic', version=0), EnvSpec(id='KrullNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KrullNoFrameskip', version=0), EnvSpec(id='Krull-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Krull', version=4), EnvSpec(id='KrullDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KrullDeterministic', version=4), EnvSpec(id='KrullNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KrullNoFrameskip', version=4), EnvSpec(id='Krull-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Krull-ram', version=0), EnvSpec(id='Krull-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Krull-ramDeterministic', version=0), EnvSpec(id='Krull-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Krull-ramNoFrameskip', version=0), EnvSpec(id='Krull-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Krull-ram', version=4), EnvSpec(id='Krull-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Krull-ramDeterministic', version=4), EnvSpec(id='Krull-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'krull', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Krull-ramNoFrameskip', version=4), EnvSpec(id='KungFuMaster-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='KungFuMaster', version=0), EnvSpec(id='KungFuMasterDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KungFuMasterDeterministic', version=0), EnvSpec(id='KungFuMasterNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KungFuMasterNoFrameskip', version=0), EnvSpec(id='KungFuMaster-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='KungFuMaster', version=4), EnvSpec(id='KungFuMasterDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KungFuMasterDeterministic', version=4), EnvSpec(id='KungFuMasterNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KungFuMasterNoFrameskip', version=4), EnvSpec(id='KungFuMaster-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='KungFuMaster-ram', version=0), EnvSpec(id='KungFuMaster-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KungFuMaster-ramDeterministic', version=0), EnvSpec(id='KungFuMaster-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KungFuMaster-ramNoFrameskip', version=0), EnvSpec(id='KungFuMaster-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='KungFuMaster-ram', version=4), EnvSpec(id='KungFuMaster-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='KungFuMaster-ramDeterministic', version=4), EnvSpec(id='KungFuMaster-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'kung_fu_master', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='KungFuMaster-ramNoFrameskip', version=4), EnvSpec(id='MontezumaRevenge-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MontezumaRevenge', version=0), EnvSpec(id='MontezumaRevengeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MontezumaRevengeDeterministic', version=0), EnvSpec(id='MontezumaRevengeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MontezumaRevengeNoFrameskip', version=0), EnvSpec(id='MontezumaRevenge-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MontezumaRevenge', version=4), EnvSpec(id='MontezumaRevengeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MontezumaRevengeDeterministic', version=4), EnvSpec(id='MontezumaRevengeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MontezumaRevengeNoFrameskip', version=4), EnvSpec(id='MontezumaRevenge-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MontezumaRevenge-ram', version=0), EnvSpec(id='MontezumaRevenge-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MontezumaRevenge-ramDeterministic', version=0), EnvSpec(id='MontezumaRevenge-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MontezumaRevenge-ramNoFrameskip', version=0), EnvSpec(id='MontezumaRevenge-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MontezumaRevenge-ram', version=4), EnvSpec(id='MontezumaRevenge-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MontezumaRevenge-ramDeterministic', version=4), EnvSpec(id='MontezumaRevenge-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'montezuma_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MontezumaRevenge-ramNoFrameskip', version=4), EnvSpec(id='MsPacman-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MsPacman', version=0), EnvSpec(id='MsPacmanDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MsPacmanDeterministic', version=0), EnvSpec(id='MsPacmanNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MsPacmanNoFrameskip', version=0), EnvSpec(id='MsPacman-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MsPacman', version=4), EnvSpec(id='MsPacmanDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MsPacmanDeterministic', version=4), EnvSpec(id='MsPacmanNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MsPacmanNoFrameskip', version=4), EnvSpec(id='MsPacman-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MsPacman-ram', version=0), EnvSpec(id='MsPacman-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MsPacman-ramDeterministic', version=0), EnvSpec(id='MsPacman-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MsPacman-ramNoFrameskip', version=0), EnvSpec(id='MsPacman-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='MsPacman-ram', version=4), EnvSpec(id='MsPacman-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='MsPacman-ramDeterministic', version=4), EnvSpec(id='MsPacman-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'ms_pacman', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='MsPacman-ramNoFrameskip', version=4), EnvSpec(id='NameThisGame-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='NameThisGame', version=0), EnvSpec(id='NameThisGameDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='NameThisGameDeterministic', version=0), EnvSpec(id='NameThisGameNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='NameThisGameNoFrameskip', version=0), EnvSpec(id='NameThisGame-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='NameThisGame', version=4), EnvSpec(id='NameThisGameDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='NameThisGameDeterministic', version=4), EnvSpec(id='NameThisGameNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='NameThisGameNoFrameskip', version=4), EnvSpec(id='NameThisGame-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='NameThisGame-ram', version=0), EnvSpec(id='NameThisGame-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='NameThisGame-ramDeterministic', version=0), EnvSpec(id='NameThisGame-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='NameThisGame-ramNoFrameskip', version=0), EnvSpec(id='NameThisGame-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='NameThisGame-ram', version=4), EnvSpec(id='NameThisGame-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='NameThisGame-ramDeterministic', version=4), EnvSpec(id='NameThisGame-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'name_this_game', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='NameThisGame-ramNoFrameskip', version=4), EnvSpec(id='Phoenix-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Phoenix', version=0), EnvSpec(id='PhoenixDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PhoenixDeterministic', version=0), EnvSpec(id='PhoenixNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PhoenixNoFrameskip', version=0), EnvSpec(id='Phoenix-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Phoenix', version=4), EnvSpec(id='PhoenixDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PhoenixDeterministic', version=4), EnvSpec(id='PhoenixNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PhoenixNoFrameskip', version=4), EnvSpec(id='Phoenix-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Phoenix-ram', version=0), EnvSpec(id='Phoenix-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Phoenix-ramDeterministic', version=0), EnvSpec(id='Phoenix-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Phoenix-ramNoFrameskip', version=0), EnvSpec(id='Phoenix-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Phoenix-ram', version=4), EnvSpec(id='Phoenix-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Phoenix-ramDeterministic', version=4), EnvSpec(id='Phoenix-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'phoenix', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Phoenix-ramNoFrameskip', version=4), EnvSpec(id='Pitfall-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pitfall', version=0), EnvSpec(id='PitfallDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PitfallDeterministic', version=0), EnvSpec(id='PitfallNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PitfallNoFrameskip', version=0), EnvSpec(id='Pitfall-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pitfall', version=4), EnvSpec(id='PitfallDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PitfallDeterministic', version=4), EnvSpec(id='PitfallNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PitfallNoFrameskip', version=4), EnvSpec(id='Pitfall-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pitfall-ram', version=0), EnvSpec(id='Pitfall-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pitfall-ramDeterministic', version=0), EnvSpec(id='Pitfall-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pitfall-ramNoFrameskip', version=0), EnvSpec(id='Pitfall-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pitfall-ram', version=4), EnvSpec(id='Pitfall-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pitfall-ramDeterministic', version=4), EnvSpec(id='Pitfall-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pitfall', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pitfall-ramNoFrameskip', version=4), EnvSpec(id='Pong-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong', version=0), EnvSpec(id='PongDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PongDeterministic', version=0), EnvSpec(id='PongNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PongNoFrameskip', version=0), EnvSpec(id='Pong-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong', version=4), EnvSpec(id='PongDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PongDeterministic', version=4), EnvSpec(id='PongNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PongNoFrameskip', version=4), EnvSpec(id='Pong-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong-ram', version=0), EnvSpec(id='Pong-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pong-ramDeterministic', version=0), EnvSpec(id='Pong-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pong-ramNoFrameskip', version=0), EnvSpec(id='Pong-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pong-ram', version=4), EnvSpec(id='Pong-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pong-ramDeterministic', version=4), EnvSpec(id='Pong-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pong', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pong-ramNoFrameskip', version=4), EnvSpec(id='Pooyan-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pooyan', version=0), EnvSpec(id='PooyanDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PooyanDeterministic', version=0), EnvSpec(id='PooyanNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PooyanNoFrameskip', version=0), EnvSpec(id='Pooyan-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pooyan', version=4), EnvSpec(id='PooyanDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PooyanDeterministic', version=4), EnvSpec(id='PooyanNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PooyanNoFrameskip', version=4), EnvSpec(id='Pooyan-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pooyan-ram', version=0), EnvSpec(id='Pooyan-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pooyan-ramDeterministic', version=0), EnvSpec(id='Pooyan-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pooyan-ramNoFrameskip', version=0), EnvSpec(id='Pooyan-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Pooyan-ram', version=4), EnvSpec(id='Pooyan-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Pooyan-ramDeterministic', version=4), EnvSpec(id='Pooyan-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'pooyan', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Pooyan-ramNoFrameskip', version=4), EnvSpec(id='PrivateEye-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='PrivateEye', version=0), EnvSpec(id='PrivateEyeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PrivateEyeDeterministic', version=0), EnvSpec(id='PrivateEyeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PrivateEyeNoFrameskip', version=0), EnvSpec(id='PrivateEye-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='PrivateEye', version=4), EnvSpec(id='PrivateEyeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PrivateEyeDeterministic', version=4), EnvSpec(id='PrivateEyeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PrivateEyeNoFrameskip', version=4), EnvSpec(id='PrivateEye-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='PrivateEye-ram', version=0), EnvSpec(id='PrivateEye-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PrivateEye-ramDeterministic', version=0), EnvSpec(id='PrivateEye-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PrivateEye-ramNoFrameskip', version=0), EnvSpec(id='PrivateEye-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='PrivateEye-ram', version=4), EnvSpec(id='PrivateEye-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='PrivateEye-ramDeterministic', version=4), EnvSpec(id='PrivateEye-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'private_eye', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='PrivateEye-ramNoFrameskip', version=4), EnvSpec(id='Qbert-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Qbert', version=0), EnvSpec(id='QbertDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='QbertDeterministic', version=0), EnvSpec(id='QbertNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='QbertNoFrameskip', version=0), EnvSpec(id='Qbert-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Qbert', version=4), EnvSpec(id='QbertDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='QbertDeterministic', version=4), EnvSpec(id='QbertNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='QbertNoFrameskip', version=4), EnvSpec(id='Qbert-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Qbert-ram', version=0), EnvSpec(id='Qbert-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Qbert-ramDeterministic', version=0), EnvSpec(id='Qbert-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Qbert-ramNoFrameskip', version=0), EnvSpec(id='Qbert-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Qbert-ram', version=4), EnvSpec(id='Qbert-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Qbert-ramDeterministic', version=4), EnvSpec(id='Qbert-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'qbert', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Qbert-ramNoFrameskip', version=4), EnvSpec(id='Riverraid-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Riverraid', version=0), EnvSpec(id='RiverraidDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RiverraidDeterministic', version=0), EnvSpec(id='RiverraidNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RiverraidNoFrameskip', version=0), EnvSpec(id='Riverraid-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Riverraid', version=4), EnvSpec(id='RiverraidDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RiverraidDeterministic', version=4), EnvSpec(id='RiverraidNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RiverraidNoFrameskip', version=4), EnvSpec(id='Riverraid-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Riverraid-ram', version=0), EnvSpec(id='Riverraid-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Riverraid-ramDeterministic', version=0), EnvSpec(id='Riverraid-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Riverraid-ramNoFrameskip', version=0), EnvSpec(id='Riverraid-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Riverraid-ram', version=4), EnvSpec(id='Riverraid-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Riverraid-ramDeterministic', version=4), EnvSpec(id='Riverraid-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'riverraid', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Riverraid-ramNoFrameskip', version=4), EnvSpec(id='RoadRunner-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='RoadRunner', version=0), EnvSpec(id='RoadRunnerDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RoadRunnerDeterministic', version=0), EnvSpec(id='RoadRunnerNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RoadRunnerNoFrameskip', version=0), EnvSpec(id='RoadRunner-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='RoadRunner', version=4), EnvSpec(id='RoadRunnerDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RoadRunnerDeterministic', version=4), EnvSpec(id='RoadRunnerNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RoadRunnerNoFrameskip', version=4), EnvSpec(id='RoadRunner-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='RoadRunner-ram', version=0), EnvSpec(id='RoadRunner-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RoadRunner-ramDeterministic', version=0), EnvSpec(id='RoadRunner-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RoadRunner-ramNoFrameskip', version=0), EnvSpec(id='RoadRunner-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='RoadRunner-ram', version=4), EnvSpec(id='RoadRunner-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RoadRunner-ramDeterministic', version=4), EnvSpec(id='RoadRunner-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'road_runner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RoadRunner-ramNoFrameskip', version=4), EnvSpec(id='Robotank-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Robotank', version=0), EnvSpec(id='RobotankDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RobotankDeterministic', version=0), EnvSpec(id='RobotankNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RobotankNoFrameskip', version=0), EnvSpec(id='Robotank-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Robotank', version=4), EnvSpec(id='RobotankDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='RobotankDeterministic', version=4), EnvSpec(id='RobotankNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='RobotankNoFrameskip', version=4), EnvSpec(id='Robotank-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Robotank-ram', version=0), EnvSpec(id='Robotank-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Robotank-ramDeterministic', version=0), EnvSpec(id='Robotank-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Robotank-ramNoFrameskip', version=0), EnvSpec(id='Robotank-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Robotank-ram', version=4), EnvSpec(id='Robotank-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Robotank-ramDeterministic', version=4), EnvSpec(id='Robotank-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'robotank', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Robotank-ramNoFrameskip', version=4), EnvSpec(id='Seaquest-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Seaquest', version=0), EnvSpec(id='SeaquestDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SeaquestDeterministic', version=0), EnvSpec(id='SeaquestNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SeaquestNoFrameskip', version=0), EnvSpec(id='Seaquest-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Seaquest', version=4), EnvSpec(id='SeaquestDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SeaquestDeterministic', version=4), EnvSpec(id='SeaquestNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SeaquestNoFrameskip', version=4), EnvSpec(id='Seaquest-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Seaquest-ram', version=0), EnvSpec(id='Seaquest-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Seaquest-ramDeterministic', version=0), EnvSpec(id='Seaquest-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Seaquest-ramNoFrameskip', version=0), EnvSpec(id='Seaquest-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Seaquest-ram', version=4), EnvSpec(id='Seaquest-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Seaquest-ramDeterministic', version=4), EnvSpec(id='Seaquest-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'seaquest', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Seaquest-ramNoFrameskip', version=4), EnvSpec(id='Skiing-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Skiing', version=0), EnvSpec(id='SkiingDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SkiingDeterministic', version=0), EnvSpec(id='SkiingNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SkiingNoFrameskip', version=0), EnvSpec(id='Skiing-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Skiing', version=4), EnvSpec(id='SkiingDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SkiingDeterministic', version=4), EnvSpec(id='SkiingNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SkiingNoFrameskip', version=4), EnvSpec(id='Skiing-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Skiing-ram', version=0), EnvSpec(id='Skiing-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Skiing-ramDeterministic', version=0), EnvSpec(id='Skiing-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Skiing-ramNoFrameskip', version=0), EnvSpec(id='Skiing-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Skiing-ram', version=4), EnvSpec(id='Skiing-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Skiing-ramDeterministic', version=4), EnvSpec(id='Skiing-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'skiing', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Skiing-ramNoFrameskip', version=4), EnvSpec(id='Solaris-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Solaris', version=0), EnvSpec(id='SolarisDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SolarisDeterministic', version=0), EnvSpec(id='SolarisNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SolarisNoFrameskip', version=0), EnvSpec(id='Solaris-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Solaris', version=4), EnvSpec(id='SolarisDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='SolarisDeterministic', version=4), EnvSpec(id='SolarisNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SolarisNoFrameskip', version=4), EnvSpec(id='Solaris-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Solaris-ram', version=0), EnvSpec(id='Solaris-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Solaris-ramDeterministic', version=0), EnvSpec(id='Solaris-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Solaris-ramNoFrameskip', version=0), EnvSpec(id='Solaris-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Solaris-ram', version=4), EnvSpec(id='Solaris-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Solaris-ramDeterministic', version=4), EnvSpec(id='Solaris-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'solaris', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Solaris-ramNoFrameskip', version=4), EnvSpec(id='SpaceInvaders-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='SpaceInvaders', version=0), EnvSpec(id='SpaceInvadersDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 3}, namespace=None, name='SpaceInvadersDeterministic', version=0), EnvSpec(id='SpaceInvadersNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=300000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SpaceInvadersNoFrameskip', version=0), EnvSpec(id='SpaceInvaders-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='SpaceInvaders', version=4), EnvSpec(id='SpaceInvadersDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 3}, namespace=None, name='SpaceInvadersDeterministic', version=4), EnvSpec(id='SpaceInvadersNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=300000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SpaceInvadersNoFrameskip', version=4), EnvSpec(id='SpaceInvaders-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='SpaceInvaders-ram', version=0), EnvSpec(id='SpaceInvaders-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 3}, namespace=None, name='SpaceInvaders-ramDeterministic', version=0), EnvSpec(id='SpaceInvaders-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=300000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SpaceInvaders-ramNoFrameskip', version=0), EnvSpec(id='SpaceInvaders-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='SpaceInvaders-ram', version=4), EnvSpec(id='SpaceInvaders-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 3}, namespace=None, name='SpaceInvaders-ramDeterministic', version=4), EnvSpec(id='SpaceInvaders-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=300000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'space_invaders', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='SpaceInvaders-ramNoFrameskip', version=4), EnvSpec(id='StarGunner-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='StarGunner', version=0), EnvSpec(id='StarGunnerDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='StarGunnerDeterministic', version=0), EnvSpec(id='StarGunnerNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='StarGunnerNoFrameskip', version=0), EnvSpec(id='StarGunner-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='StarGunner', version=4), EnvSpec(id='StarGunnerDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='StarGunnerDeterministic', version=4), EnvSpec(id='StarGunnerNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='StarGunnerNoFrameskip', version=4), EnvSpec(id='StarGunner-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='StarGunner-ram', version=0), EnvSpec(id='StarGunner-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='StarGunner-ramDeterministic', version=0), EnvSpec(id='StarGunner-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='StarGunner-ramNoFrameskip', version=0), EnvSpec(id='StarGunner-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='StarGunner-ram', version=4), EnvSpec(id='StarGunner-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='StarGunner-ramDeterministic', version=4), EnvSpec(id='StarGunner-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'star_gunner', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='StarGunner-ramNoFrameskip', version=4), EnvSpec(id='Tennis-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tennis', version=0), EnvSpec(id='TennisDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TennisDeterministic', version=0), EnvSpec(id='TennisNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TennisNoFrameskip', version=0), EnvSpec(id='Tennis-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tennis', version=4), EnvSpec(id='TennisDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TennisDeterministic', version=4), EnvSpec(id='TennisNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TennisNoFrameskip', version=4), EnvSpec(id='Tennis-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tennis-ram', version=0), EnvSpec(id='Tennis-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Tennis-ramDeterministic', version=0), EnvSpec(id='Tennis-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Tennis-ramNoFrameskip', version=0), EnvSpec(id='Tennis-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tennis-ram', version=4), EnvSpec(id='Tennis-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Tennis-ramDeterministic', version=4), EnvSpec(id='Tennis-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tennis', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Tennis-ramNoFrameskip', version=4), EnvSpec(id='TimePilot-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='TimePilot', version=0), EnvSpec(id='TimePilotDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TimePilotDeterministic', version=0), EnvSpec(id='TimePilotNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TimePilotNoFrameskip', version=0), EnvSpec(id='TimePilot-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='TimePilot', version=4), EnvSpec(id='TimePilotDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TimePilotDeterministic', version=4), EnvSpec(id='TimePilotNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TimePilotNoFrameskip', version=4), EnvSpec(id='TimePilot-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='TimePilot-ram', version=0), EnvSpec(id='TimePilot-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TimePilot-ramDeterministic', version=0), EnvSpec(id='TimePilot-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TimePilot-ramNoFrameskip', version=0), EnvSpec(id='TimePilot-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='TimePilot-ram', version=4), EnvSpec(id='TimePilot-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TimePilot-ramDeterministic', version=4), EnvSpec(id='TimePilot-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'time_pilot', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TimePilot-ramNoFrameskip', version=4), EnvSpec(id='Tutankham-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tutankham', version=0), EnvSpec(id='TutankhamDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TutankhamDeterministic', version=0), EnvSpec(id='TutankhamNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TutankhamNoFrameskip', version=0), EnvSpec(id='Tutankham-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tutankham', version=4), EnvSpec(id='TutankhamDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='TutankhamDeterministic', version=4), EnvSpec(id='TutankhamNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='TutankhamNoFrameskip', version=4), EnvSpec(id='Tutankham-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tutankham-ram', version=0), EnvSpec(id='Tutankham-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Tutankham-ramDeterministic', version=0), EnvSpec(id='Tutankham-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Tutankham-ramNoFrameskip', version=0), EnvSpec(id='Tutankham-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Tutankham-ram', version=4), EnvSpec(id='Tutankham-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Tutankham-ramDeterministic', version=4), EnvSpec(id='Tutankham-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'tutankham', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Tutankham-ramNoFrameskip', version=4), EnvSpec(id='UpNDown-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='UpNDown', version=0), EnvSpec(id='UpNDownDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='UpNDownDeterministic', version=0), EnvSpec(id='UpNDownNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='UpNDownNoFrameskip', version=0), EnvSpec(id='UpNDown-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='UpNDown', version=4), EnvSpec(id='UpNDownDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='UpNDownDeterministic', version=4), EnvSpec(id='UpNDownNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='UpNDownNoFrameskip', version=4), EnvSpec(id='UpNDown-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='UpNDown-ram', version=0), EnvSpec(id='UpNDown-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='UpNDown-ramDeterministic', version=0), EnvSpec(id='UpNDown-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='UpNDown-ramNoFrameskip', version=0), EnvSpec(id='UpNDown-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='UpNDown-ram', version=4), EnvSpec(id='UpNDown-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='UpNDown-ramDeterministic', version=4), EnvSpec(id='UpNDown-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'up_n_down', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='UpNDown-ramNoFrameskip', version=4), EnvSpec(id='Venture-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Venture', version=0), EnvSpec(id='VentureDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VentureDeterministic', version=0), EnvSpec(id='VentureNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VentureNoFrameskip', version=0), EnvSpec(id='Venture-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Venture', version=4), EnvSpec(id='VentureDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VentureDeterministic', version=4), EnvSpec(id='VentureNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VentureNoFrameskip', version=4), EnvSpec(id='Venture-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Venture-ram', version=0), EnvSpec(id='Venture-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Venture-ramDeterministic', version=0), EnvSpec(id='Venture-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Venture-ramNoFrameskip', version=0), EnvSpec(id='Venture-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Venture-ram', version=4), EnvSpec(id='Venture-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Venture-ramDeterministic', version=4), EnvSpec(id='Venture-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'venture', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Venture-ramNoFrameskip', version=4), EnvSpec(id='VideoPinball-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='VideoPinball', version=0), EnvSpec(id='VideoPinballDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VideoPinballDeterministic', version=0), EnvSpec(id='VideoPinballNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VideoPinballNoFrameskip', version=0), EnvSpec(id='VideoPinball-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='VideoPinball', version=4), EnvSpec(id='VideoPinballDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VideoPinballDeterministic', version=4), EnvSpec(id='VideoPinballNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VideoPinballNoFrameskip', version=4), EnvSpec(id='VideoPinball-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='VideoPinball-ram', version=0), EnvSpec(id='VideoPinball-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VideoPinball-ramDeterministic', version=0), EnvSpec(id='VideoPinball-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VideoPinball-ramNoFrameskip', version=0), EnvSpec(id='VideoPinball-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='VideoPinball-ram', version=4), EnvSpec(id='VideoPinball-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='VideoPinball-ramDeterministic', version=4), EnvSpec(id='VideoPinball-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'video_pinball', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='VideoPinball-ramNoFrameskip', version=4), EnvSpec(id='WizardOfWor-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='WizardOfWor', version=0), EnvSpec(id='WizardOfWorDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='WizardOfWorDeterministic', version=0), EnvSpec(id='WizardOfWorNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='WizardOfWorNoFrameskip', version=0), EnvSpec(id='WizardOfWor-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='WizardOfWor', version=4), EnvSpec(id='WizardOfWorDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='WizardOfWorDeterministic', version=4), EnvSpec(id='WizardOfWorNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='WizardOfWorNoFrameskip', version=4), EnvSpec(id='WizardOfWor-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='WizardOfWor-ram', version=0), EnvSpec(id='WizardOfWor-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='WizardOfWor-ramDeterministic', version=0), EnvSpec(id='WizardOfWor-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='WizardOfWor-ramNoFrameskip', version=0), EnvSpec(id='WizardOfWor-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='WizardOfWor-ram', version=4), EnvSpec(id='WizardOfWor-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='WizardOfWor-ramDeterministic', version=4), EnvSpec(id='WizardOfWor-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'wizard_of_wor', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='WizardOfWor-ramNoFrameskip', version=4), EnvSpec(id='YarsRevenge-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='YarsRevenge', version=0), EnvSpec(id='YarsRevengeDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='YarsRevengeDeterministic', version=0), EnvSpec(id='YarsRevengeNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='YarsRevengeNoFrameskip', version=0), EnvSpec(id='YarsRevenge-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='YarsRevenge', version=4), EnvSpec(id='YarsRevengeDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='YarsRevengeDeterministic', version=4), EnvSpec(id='YarsRevengeNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='YarsRevengeNoFrameskip', version=4), EnvSpec(id='YarsRevenge-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='YarsRevenge-ram', version=0), EnvSpec(id='YarsRevenge-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='YarsRevenge-ramDeterministic', version=0), EnvSpec(id='YarsRevenge-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='YarsRevenge-ramNoFrameskip', version=0), EnvSpec(id='YarsRevenge-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='YarsRevenge-ram', version=4), EnvSpec(id='YarsRevenge-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='YarsRevenge-ramDeterministic', version=4), EnvSpec(id='YarsRevenge-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'yars_revenge', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='YarsRevenge-ramNoFrameskip', version=4), EnvSpec(id='Zaxxon-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Zaxxon', version=0), EnvSpec(id='ZaxxonDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ZaxxonDeterministic', version=0), EnvSpec(id='ZaxxonNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ZaxxonNoFrameskip', version=0), EnvSpec(id='Zaxxon-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Zaxxon', version=4), EnvSpec(id='ZaxxonDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='ZaxxonDeterministic', version=4), EnvSpec(id='ZaxxonNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'rgb', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='ZaxxonNoFrameskip', version=4), EnvSpec(id='Zaxxon-ram-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=10000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Zaxxon-ram', version=0), EnvSpec(id='Zaxxon-ramDeterministic-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Zaxxon-ramDeterministic', version=0), EnvSpec(id='Zaxxon-ramNoFrameskip-v0', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.25, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Zaxxon-ramNoFrameskip', version=0), EnvSpec(id='Zaxxon-ram-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': (2, 5)}, namespace=None, name='Zaxxon-ram', version=4), EnvSpec(id='Zaxxon-ramDeterministic-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=100000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 4}, namespace=None, name='Zaxxon-ramDeterministic', version=4), EnvSpec(id='Zaxxon-ramNoFrameskip-v4', entry_point='gym.envs.atari:AtariEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=400000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'game': 'zaxxon', 'obs_type': 'ram', 'repeat_action_probability': 0.0, 'full_action_space': False, 'frameskip': 1}, namespace=None, name='Zaxxon-ramNoFrameskip', version=4), EnvSpec(id='CartPole-v0', entry_point='gym.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=195.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='CartPole', version=0), EnvSpec(id='CartPole-v1', entry_point='gym.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=475.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='CartPole', version=1), EnvSpec(id='MountainCar-v0', entry_point='gym.envs.classic_control.mountain_car:MountainCarEnv', reward_threshold=-110.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='MountainCar', version=0), EnvSpec(id='MountainCarContinuous-v0', entry_point='gym.envs.classic_control.continuous_mountain_car:Continuous_MountainCarEnv', reward_threshold=90.0, nondeterministic=False, max_episode_steps=999, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='MountainCarContinuous', version=0), EnvSpec(id='Pendulum-v1', entry_point='gym.envs.classic_control.pendulum:PendulumEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Pendulum', version=1), EnvSpec(id='Acrobot-v1', entry_point='gym.envs.classic_control.acrobot:AcrobotEnv', reward_threshold=-100.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Acrobot', version=1), EnvSpec(id='LunarLander-v2', entry_point='gym.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='LunarLander', version=2), EnvSpec(id='LunarLanderContinuous-v2', entry_point='gym.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'continuous': True}, namespace=None, name='LunarLanderContinuous', version=2), EnvSpec(id='BipedalWalker-v3', entry_point='gym.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=1600, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='BipedalWalker', version=3), EnvSpec(id='BipedalWalkerHardcore-v3', entry_point='gym.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=2000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'hardcore': True}, namespace=None, name='BipedalWalkerHardcore', version=3), EnvSpec(id='CarRacing-v2', entry_point='gym.envs.box2d.car_racing:CarRacing', reward_threshold=900, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='CarRacing', version=2), EnvSpec(id='Blackjack-v1', entry_point='gym.envs.toy_text.blackjack:BlackjackEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'sab': True, 'natural': False}, namespace=None, name='Blackjack', version=1), EnvSpec(id='FrozenLake-v1', entry_point='gym.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.7, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'map_name': '4x4'}, namespace=None, name='FrozenLake', version=1), EnvSpec(id='FrozenLake8x8-v1', entry_point='gym.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.85, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={'map_name': '8x8'}, namespace=None, name='FrozenLake8x8', version=1), EnvSpec(id='CliffWalking-v0', entry_point='gym.envs.toy_text.cliffwalking:CliffWalkingEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='CliffWalking', version=0), EnvSpec(id='Taxi-v3', entry_point='gym.envs.toy_text.taxi:TaxiEnv', reward_threshold=8, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Taxi', version=3), EnvSpec(id='Reacher-v2', entry_point='gym.envs.mujoco:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Reacher', version=2), EnvSpec(id='Reacher-v4', entry_point='gym.envs.mujoco.reacher_v4:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Reacher', version=4), EnvSpec(id='Pusher-v2', entry_point='gym.envs.mujoco:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Pusher', version=2), EnvSpec(id='Pusher-v4', entry_point='gym.envs.mujoco.pusher_v4:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Pusher', version=4), EnvSpec(id='InvertedPendulum-v2', entry_point='gym.envs.mujoco:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='InvertedPendulum', version=2), EnvSpec(id='InvertedPendulum-v4', entry_point='gym.envs.mujoco.inverted_pendulum_v4:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='InvertedPendulum', version=4), EnvSpec(id='InvertedDoublePendulum-v2', entry_point='gym.envs.mujoco:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=2), EnvSpec(id='InvertedDoublePendulum-v4', entry_point='gym.envs.mujoco.inverted_double_pendulum_v4:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=4), EnvSpec(id='HalfCheetah-v2', entry_point='gym.envs.mujoco:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HalfCheetah', version=2), EnvSpec(id='HalfCheetah-v3', entry_point='gym.envs.mujoco.half_cheetah_v3:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HalfCheetah', version=3), EnvSpec(id='HalfCheetah-v4', entry_point='gym.envs.mujoco.half_cheetah_v4:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HalfCheetah', version=4), EnvSpec(id='Hopper-v2', entry_point='gym.envs.mujoco:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Hopper', version=2), EnvSpec(id='Hopper-v3', entry_point='gym.envs.mujoco.hopper_v3:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Hopper', version=3), EnvSpec(id='Hopper-v4', entry_point='gym.envs.mujoco.hopper_v4:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Hopper', version=4), EnvSpec(id='Swimmer-v2', entry_point='gym.envs.mujoco:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Swimmer', version=2), EnvSpec(id='Swimmer-v3', entry_point='gym.envs.mujoco.swimmer_v3:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Swimmer', version=3), EnvSpec(id='Swimmer-v4', entry_point='gym.envs.mujoco.swimmer_v4:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Swimmer', version=4), EnvSpec(id='Walker2d-v2', entry_point='gym.envs.mujoco:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Walker2d', version=2), EnvSpec(id='Walker2d-v3', entry_point='gym.envs.mujoco.walker2d_v3:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Walker2d', version=3), EnvSpec(id='Walker2d-v4', entry_point='gym.envs.mujoco.walker2d_v4:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Walker2d', version=4), EnvSpec(id='Ant-v2', entry_point='gym.envs.mujoco:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Ant', version=2), EnvSpec(id='Ant-v3', entry_point='gym.envs.mujoco.ant_v3:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Ant', version=3), EnvSpec(id='Ant-v4', entry_point='gym.envs.mujoco.ant_v4:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Ant', version=4), EnvSpec(id='Humanoid-v2', entry_point='gym.envs.mujoco:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Humanoid', version=2), EnvSpec(id='Humanoid-v3', entry_point='gym.envs.mujoco.humanoid_v3:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Humanoid', version=3), EnvSpec(id='Humanoid-v4', entry_point='gym.envs.mujoco.humanoid_v4:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='Humanoid', version=4), EnvSpec(id='HumanoidStandup-v2', entry_point='gym.envs.mujoco:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HumanoidStandup', version=2), EnvSpec(id='HumanoidStandup-v4', entry_point='gym.envs.mujoco.humanoidstandup_v4:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, new_step_api=False, kwargs={}, namespace=None, name='HumanoidStandup', version=4)])\n"]}],"source":["# List of available environments\n","\n","print(gym.envs.registry.all())"]},{"cell_type":"markdown","metadata":{"id":"_wJkENOhHAOY"},"source":["### Configure parameters\n","\n","We will be using an epsilon-greedy algorithm for choosing the best action, where there is an epsilon chance of sampling a random action from the action space. Instead of using epsilon decay, we will be using linear annealing to decrease epsilon from 1 to 0.1 over 1 million frames by Deepmind’s specification."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"YArr9GLVHAOZ","executionInfo":{"status":"ok","timestamp":1720235584169,"user_tz":-330,"elapsed":615,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"outputs":[],"source":["seed = 42\n","\n","# Discount factor for past rewards\n","gamma = 0.99\n","\n","# Epsilon greedy parameter\n","epsilon = 1.0\n","\n","# Minimum epsilon greedy parameter\n","epsilon_min = 0.1\n","\n","# Maximum epsilon greedy parameter\n","epsilon_max = 1.0\n","\n","# Rate at which to reduce chance of random action being taken\n","epsilon_interval = (epsilon_max - epsilon_min)\n","\n","# Size of batch taken from replay buffer\n","batch_size = 32\n","\n","# Number of frames to run\n","max_steps_per_episode = 10000"]},{"cell_type":"markdown","metadata":{"id":"4ECYMkVVHAOZ"},"source":["Next, we define functions used to show the video by adding it to the CoLab notebook"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"v1ddymg9HAOZ","executionInfo":{"status":"ok","timestamp":1720235591272,"user_tz":-330,"elapsed":841,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"outputs":[],"source":["display = Display(visible=0, size=(1400, 900))\n","display.start()\n","\n","\"\"\" Utility functions to enable video recording of gym environment and displaying it.\n","To enable video, we just do \"env = wrap_env(env) \"\"\"\n","\n","def show_video():\n","  mp4list = glob.glob('video/*.mp4')\n","  if len(mp4list) > 0:\n","    mp4 = mp4list[0]\n","    video = io.open(mp4, 'r+b').read()\n","    encoded = base64.b64encode(video)\n","    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","  else:\n","    print(\"Could not find video\")\n","\n","\n","def wrap_env(env):\n","    try:\n","        env = gnwrapper.Monitor(env, './video', \"recording\")\n","    except:\n","        env = gnwrapper.Monitor(env, './video', \"recording\")\n","\n","    clear_output(wait=True)\n","    return env\n"]},{"cell_type":"markdown","metadata":{"id":"g3pDVsJiHAOa"},"source":["### Instantiate the environment\n","\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"PlrslBIxHAOa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ce32e200-d8de-4077-c2be-f1674fa687a2","executionInfo":{"status":"ok","timestamp":1720235596721,"user_tz":-330,"elapsed":589,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3444837047, 2669555309)"]},"metadata":{},"execution_count":9}],"source":["# Create Pacman environment\n","# Initialize the environment 'ALE/MsPacman-v5'.\n","\n","env = wrap_env(gym.make('ALE/MsPacman-v5', render_mode=\"rgb_array\"))\n","env.seed(seed)   # setting seed for reproducibility"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"NF8vcN0rTTJV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"95442e50-9a0e-4457-a5bb-f259ebb18f13","executionInfo":{"status":"ok","timestamp":1720235602467,"user_tz":-330,"elapsed":1090,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["State shape:  (210, 160, 3)\n","Number of actions:  9\n"]}],"source":["print('State shape: ', env.observation_space.shape)\n","print('Number of actions: ', env.action_space.n)"]},{"cell_type":"markdown","metadata":{"id":"laKtW9JAHAOa"},"source":["### Create the Deep Q-Network Model\n","\n","Deep Q-network learns an approximation of the Q-table, which is a mapping between the states and actions that an agent will take. For every state in Pacman environment, we'll have nine actions that can be taken.\n","\n","The environment provides the state, and the action is chosen by selecting the larger of the nine Q-values predicted in the output layer."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"L-aZkypvHAOa","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6471926f-90ed-43a4-f87a-864eeef92818","executionInfo":{"status":"ok","timestamp":1720235637285,"user_tz":-330,"elapsed":618,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(210, 160, 3)"]},"metadata":{},"execution_count":11}],"source":["# Resets the environment to an initial state and returns an initial observation.\n","# Shape of observation or state\n","env.reset().shape"]},{"cell_type":"markdown","metadata":{"id":"AolxuOcj9q4p"},"source":["Refer to the following [Deepmind paper](https://arxiv.org/pdf/1312.5602v1.pdf) for playing Atari with Deep Reinforcement Learning"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"SgATLM--HAOb","executionInfo":{"status":"ok","timestamp":1720235644240,"user_tz":-330,"elapsed":577,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"outputs":[],"source":["# Write a funtion for model creation\n","num_actions = 9\n","\n","def create_q_model():\n","\n","    # Network defined by the Deepmind paper\n","    inputs = layers.Input(shape=(210, 160, 3))\n","\n","    # Convolutions on the frames of the screen\n","    layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(inputs)\n","    layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n","    layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n","\n","    layer4 = layers.Flatten()(layer3)\n","\n","    layer5 = layers.Dense(512, activation=\"relu\")(layer4)\n","    action = layers.Dense(num_actions, activation=\"linear\")(layer5)\n","\n","    return keras.Model(inputs=inputs, outputs=action)\n"]},{"cell_type":"markdown","metadata":{"id":"6t4n9Me9HAOb"},"source":["The first model makes the predictions for Q-values which are used to take an action."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"fos3rgMLHAOb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ba1b7593-307d-4444-a258-575c03980fa1","executionInfo":{"status":"ok","timestamp":1720235649571,"user_tz":-330,"elapsed":2158,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 210, 160, 3)]     0         \n","                                                                 \n"," conv2d (Conv2D)             (None, 51, 39, 32)        6176      \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 24, 18, 64)        32832     \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 22, 16, 64)        36928     \n","                                                                 \n"," flatten (Flatten)           (None, 22528)             0         \n","                                                                 \n"," dense (Dense)               (None, 512)               11534848  \n","                                                                 \n"," dense_1 (Dense)             (None, 9)                 4617      \n","                                                                 \n","=================================================================\n","Total params: 11615401 (44.31 MB)\n","Trainable params: 11615401 (44.31 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["# Create model\n","model = create_q_model()\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"99cNxGbnHAOb"},"source":["Now build a target model for the prediction of future rewards. Since the same network is calculating the predicted value and the target value, there could be a lot of divergence between these two. So, instead of using one neural network for learning, we can use two.\n","\n","The weights of a target model get updated every 10000 steps thus when the loss between the Q-values is calculated the target Q-value is stable."]},{"cell_type":"code","execution_count":15,"metadata":{"id":"h2Er6a13HAOc","executionInfo":{"status":"ok","timestamp":1720235694356,"user_tz":-330,"elapsed":596,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"outputs":[],"source":["# Create target model\n","model_target = create_q_model()"]},{"cell_type":"markdown","metadata":{"id":"0IO5H_7DHAOc"},"source":["### Train the Model\n","\n","The following pseudo-algorithm implements deep Q-learning with experience replay.\n","\n","\n","<br><br>\n","\n","<center>\n","<img src=\"https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/deep_Q_learning.png\" width=480px, height=480px/>\n","</center>\n","<br><br>\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eibJgnoYU31l"},"source":["**Note:** The below code cell might take some time to run, suggesting to use GPU. Refer to the following [link](https://towardsdatascience.com/reinforcement-learning-explained-visually-part-5-deep-q-networks-step-by-step-5a5317197f4b) for the more details of Training the Deep-Q Networks"]},{"cell_type":"code","source":["# In the Deepmind paper they use RMSProp however then Adam optimizer\n","# improves training time\n","optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n","\n","# Experience replay buffers\n","# Reinforcement learning algorithms use replay buffers to store trajectories of experience\n","# when executing a policy in an environment. During training, replay buffers are queried for a\n","# subset of the trajectories (either a sequential subset or a sample) to \"replay\" the agent's experience\n","action_history = []\n","state_history = []\n","state_next_history = []\n","rewards_history = []\n","done_history = []\n","episode_reward_history = []\n","running_reward = 0\n","episode_count = 0\n","frame_count = 0\n","\n","# Number of frames to take random action and observe output\n","epsilon_random_frames = 50000\n","\n","# Number of frames for exploration\n","epsilon_greedy_frames = 1000000.0\n","\n","# Maximum replay length\n","max_memory_length = 100000\n","\n","# Train the model after 4 actions\n","update_after_actions = 4\n","\n","# How often to update the target network\n","update_target_network = 10000\n","\n","# Using huber loss for stability and also to avoid exploding gradients\n","# Huber loss is a combination of linear as well as quadratic scoring methods.\n","# It has an additional hyperparameter delta (δ). Loss is linear for values above delta and quadratic below delta.\n","# Compared with MSE, Huber Loss is less sensitive to outliers as if the loss is too much\n","# it changes quadratic equation to linear and hence is a combination of both MSE and MAE.\n","loss_function = keras.losses.Huber()\n","\n","while True:  # Run until solved\n","    state = np.array(env.reset())\n","    episode_reward = 0\n","\n","    # episodes - This indicates how many games we want the agent to play in order to train itself\n","    for timestep in range(1, max_steps_per_episode):\n","        frame_count += 1\n","\n","        # Use epsilon-greedy for exploration to select an action\n","        if frame_count < epsilon_random_frames or epsilon > np.random.rand(1)[0]:\n","            # With the probability epsilon, we take random action\n","            action = np.random.choice(num_actions)\n","        else:\n","            # Predict action Q-values\n","            # From environment state\n","            state_tensor = tf.convert_to_tensor(state)\n","            state_tensor = tf.expand_dims(state_tensor, 0)\n","            action_probs = model(state_tensor, training=False)\n","            # Take best action\n","            # with probability 1-epsilon, we select an action that has a maximum Q-value\n","            action = tf.argmax(action_probs[0]).numpy()\n","\n","        # Decay probability of taking random action\n","        # Hence, a decaying epsilon ensures that our agent does not rely upon the\n","        # random predictions at the initial training epochs, only to later on exploit\n","        # its own predictions more aggressively as the Q-function converges to more consistent predictions.\n","        epsilon -= epsilon_interval / epsilon_greedy_frames\n","        epsilon = max(epsilon, epsilon_min)\n","\n","        # Is used to display the environment image\n","        env.render()\n","\n","        # Apply the sampled action in our environment\n","        # env.step - executes the given action and returns four values\n","        state_next, reward, done, _ = env.step(action)\n","        state_next = np.array(state_next)\n","\n","        episode_reward += reward\n","\n","        # Save actions and states in replay buffer\n","        action_history.append(action)\n","        state_history.append(state)\n","        state_next_history.append(state_next)\n","        done_history.append(done)\n","        rewards_history.append(reward)\n","        state = state_next\n","\n","        # Update every fourth frame and once batch size is over 32\n","        if frame_count % update_after_actions == 0 and len(done_history) > batch_size:\n","\n","            # Get indices of samples for replay buffers\n","            indices = np.random.choice(range(len(done_history)), size=batch_size)\n","\n","            # Using list comprehension to sample from replay buffer\n","            state_sample = np.array([state_history[i] for i in indices])\n","            state_next_sample = np.array([state_next_history[i] for i in indices])\n","            rewards_sample = [rewards_history[i] for i in indices]\n","            action_sample = [action_history[i] for i in indices]\n","            done_sample = tf.convert_to_tensor([float(done_history[i]) for i in indices])\n","\n","            # Build the updated Q-values for the sampled future states\n","            # Use the target model for stability\n","            # The Target network takes the next state from each data sample and predicts\n","            # the best (max predicted Q value) out of all actions that can be taken from that state. This is the ‘Target Q Value’\n","            future_rewards = model_target.predict(state_next_sample, verbose=0)\n","\n","            # Q value = reward + discount factor * expected future reward\n","            # Compute Q value\n","            updated_q_values = rewards_sample + gamma * tf.reduce_max(future_rewards, axis=1)\n","\n","            # If final frame set the last value to -1\n","            updated_q_values = updated_q_values * (1 - done_sample) - done_sample\n","\n","            # Create a mask so we only calculate loss on the updated Q-values\n","            masks = tf.one_hot(action_sample, num_actions)\n","\n","            with tf.GradientTape() as tape:\n","\n","                # Train the model on the states and updated Q-values\n","                # The Q network takes the current state and action from each data sample\n","                # and predicts the Q value for that particular action. This is the ‘Predicted Q Value’.\n","                q_values = model(state_sample)\n","\n","                # Apply the masks to the Q-values to get the Q-value for action taken\n","                q_action = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n","\n","                # Calculate loss between new Q-value and old Q-value\n","                loss = loss_function(updated_q_values, q_action)\n","\n","            # Backpropagation\n","            # after we compute the loss using the given loss function, and we use the tape to compute\n","            # the gradient of the loss with regard to the model’s trainable variables. Again,\n","            # these gradients will be tweaked later, before we apply them, depending on how good or bad the action turned out to be.\n","            grads = tape.gradient(loss, model.trainable_variables)\n","            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","        if frame_count % update_target_network == 0:\n","            # update the target network with new weights\n","            model_target.set_weights(model.get_weights())\n","            # Log details\n","            template = \"running reward: {:.2f} at episode {}, frame count {}\"\n","            print(template.format(running_reward, episode_count, frame_count))\n","\n","        # Limit the state and reward history\n","        if len(rewards_history) > max_memory_length:\n","            del rewards_history[:1]\n","            del state_history[:1]\n","            del state_next_history[:1]\n","            del action_history[:1]\n","            del done_history[:1]\n","\n","        if done:\n","            break\n","\n","        if timestep%50 == 0:\n","            print(f\"Episode: {episode_count}, Reward: {running_reward}, Timestep: {timestep} !\")\n","\n","    # Update running reward to check condition for solving\n","    episode_reward_history.append(episode_reward)\n","    if len(episode_reward_history) > 100:\n","        del episode_reward_history[:1]\n","    running_reward = np.mean(episode_reward_history)\n","\n","    episode_count += 1\n","\n","    # Condition to consider the task solved\n","    # Note that this execution may take more than 15 minutes\n","    if running_reward > 400 or episode_count > 50:\n","        print(f\"Reward: {running_reward} \\nStopped at episode {episode_count}!\")\n","        break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Iucmv2uEQPi","outputId":"7c85d3af-4cd0-4fce-ea3d-82d885a3d33b","executionInfo":{"status":"ok","timestamp":1720236668185,"user_tz":-330,"elapsed":753077,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x798944cd5a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x798944cd5a20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["Episode: 0, Reward: 0, Timestep: 50 !\n","Episode: 0, Reward: 0, Timestep: 100 !\n","Episode: 0, Reward: 0, Timestep: 150 !\n","Episode: 0, Reward: 0, Timestep: 200 !\n","Episode: 0, Reward: 0, Timestep: 250 !\n","Episode: 0, Reward: 0, Timestep: 300 !\n","Episode: 0, Reward: 0, Timestep: 350 !\n","Episode: 0, Reward: 0, Timestep: 400 !\n","Episode: 0, Reward: 0, Timestep: 450 !\n","Episode: 1, Reward: 180.0, Timestep: 50 !\n","Episode: 1, Reward: 180.0, Timestep: 100 !\n","Episode: 1, Reward: 180.0, Timestep: 150 !\n","Episode: 1, Reward: 180.0, Timestep: 200 !\n","Episode: 1, Reward: 180.0, Timestep: 250 !\n","Episode: 1, Reward: 180.0, Timestep: 300 !\n","Episode: 1, Reward: 180.0, Timestep: 350 !\n","Episode: 1, Reward: 180.0, Timestep: 400 !\n","Episode: 1, Reward: 180.0, Timestep: 450 !\n","Episode: 1, Reward: 180.0, Timestep: 500 !\n","Episode: 2, Reward: 235.0, Timestep: 50 !\n","Episode: 2, Reward: 235.0, Timestep: 100 !\n","Episode: 2, Reward: 235.0, Timestep: 150 !\n","Episode: 2, Reward: 235.0, Timestep: 200 !\n","Episode: 2, Reward: 235.0, Timestep: 250 !\n","Episode: 2, Reward: 235.0, Timestep: 300 !\n","Episode: 2, Reward: 235.0, Timestep: 350 !\n","Episode: 2, Reward: 235.0, Timestep: 400 !\n","Episode: 2, Reward: 235.0, Timestep: 450 !\n","Episode: 3, Reward: 240.0, Timestep: 50 !\n","Episode: 3, Reward: 240.0, Timestep: 100 !\n","Episode: 3, Reward: 240.0, Timestep: 150 !\n","Episode: 3, Reward: 240.0, Timestep: 200 !\n","Episode: 3, Reward: 240.0, Timestep: 250 !\n","Episode: 3, Reward: 240.0, Timestep: 300 !\n","Episode: 3, Reward: 240.0, Timestep: 350 !\n","Episode: 3, Reward: 240.0, Timestep: 400 !\n","Episode: 3, Reward: 240.0, Timestep: 450 !\n","Episode: 3, Reward: 240.0, Timestep: 500 !\n","Episode: 4, Reward: 267.5, Timestep: 50 !\n","Episode: 4, Reward: 267.5, Timestep: 100 !\n","Episode: 4, Reward: 267.5, Timestep: 150 !\n","Episode: 4, Reward: 267.5, Timestep: 200 !\n","Episode: 4, Reward: 267.5, Timestep: 250 !\n","Episode: 4, Reward: 267.5, Timestep: 300 !\n","Episode: 4, Reward: 267.5, Timestep: 350 !\n","Episode: 4, Reward: 267.5, Timestep: 400 !\n","Episode: 4, Reward: 267.5, Timestep: 450 !\n","Episode: 5, Reward: 260.0, Timestep: 50 !\n","Episode: 5, Reward: 260.0, Timestep: 100 !\n","Episode: 5, Reward: 260.0, Timestep: 150 !\n","Episode: 5, Reward: 260.0, Timestep: 200 !\n","Episode: 5, Reward: 260.0, Timestep: 250 !\n","Episode: 5, Reward: 260.0, Timestep: 300 !\n","Episode: 5, Reward: 260.0, Timestep: 350 !\n","Episode: 5, Reward: 260.0, Timestep: 400 !\n","Episode: 5, Reward: 260.0, Timestep: 450 !\n","Episode: 5, Reward: 260.0, Timestep: 500 !\n","Episode: 6, Reward: 258.3333333333333, Timestep: 50 !\n","Episode: 6, Reward: 258.3333333333333, Timestep: 100 !\n","Episode: 6, Reward: 258.3333333333333, Timestep: 150 !\n","Episode: 6, Reward: 258.3333333333333, Timestep: 200 !\n","Episode: 6, Reward: 258.3333333333333, Timestep: 250 !\n","Episode: 6, Reward: 258.3333333333333, Timestep: 300 !\n","Episode: 6, Reward: 258.3333333333333, Timestep: 350 !\n","Episode: 6, Reward: 258.3333333333333, Timestep: 400 !\n","Episode: 6, Reward: 258.3333333333333, Timestep: 450 !\n","Episode: 7, Reward: 241.42857142857142, Timestep: 50 !\n","Episode: 7, Reward: 241.42857142857142, Timestep: 100 !\n","Episode: 7, Reward: 241.42857142857142, Timestep: 150 !\n","Episode: 7, Reward: 241.42857142857142, Timestep: 200 !\n","Episode: 7, Reward: 241.42857142857142, Timestep: 250 !\n","Episode: 7, Reward: 241.42857142857142, Timestep: 300 !\n","Episode: 7, Reward: 241.42857142857142, Timestep: 350 !\n","Episode: 7, Reward: 241.42857142857142, Timestep: 400 !\n","Episode: 7, Reward: 241.42857142857142, Timestep: 450 !\n","Episode: 7, Reward: 241.42857142857142, Timestep: 500 !\n","Episode: 7, Reward: 241.42857142857142, Timestep: 550 !\n","Episode: 8, Reward: 242.5, Timestep: 50 !\n","Episode: 8, Reward: 242.5, Timestep: 100 !\n","Episode: 8, Reward: 242.5, Timestep: 150 !\n","Episode: 8, Reward: 242.5, Timestep: 200 !\n","Episode: 8, Reward: 242.5, Timestep: 250 !\n","Episode: 8, Reward: 242.5, Timestep: 300 !\n","Episode: 8, Reward: 242.5, Timestep: 350 !\n","Episode: 8, Reward: 242.5, Timestep: 400 !\n","Episode: 8, Reward: 242.5, Timestep: 450 !\n","Episode: 8, Reward: 242.5, Timestep: 500 !\n","Episode: 8, Reward: 242.5, Timestep: 550 !\n","Episode: 9, Reward: 243.33333333333334, Timestep: 50 !\n","Episode: 9, Reward: 243.33333333333334, Timestep: 100 !\n","Episode: 9, Reward: 243.33333333333334, Timestep: 150 !\n","Episode: 9, Reward: 243.33333333333334, Timestep: 200 !\n","Episode: 9, Reward: 243.33333333333334, Timestep: 250 !\n","Episode: 9, Reward: 243.33333333333334, Timestep: 300 !\n","Episode: 9, Reward: 243.33333333333334, Timestep: 350 !\n","Episode: 9, Reward: 243.33333333333334, Timestep: 400 !\n","Episode: 9, Reward: 243.33333333333334, Timestep: 450 !\n","Episode: 10, Reward: 243.0, Timestep: 50 !\n","Episode: 10, Reward: 243.0, Timestep: 100 !\n","Episode: 10, Reward: 243.0, Timestep: 150 !\n","Episode: 10, Reward: 243.0, Timestep: 200 !\n","Episode: 10, Reward: 243.0, Timestep: 250 !\n","Episode: 10, Reward: 243.0, Timestep: 300 !\n","Episode: 10, Reward: 243.0, Timestep: 350 !\n","Episode: 10, Reward: 243.0, Timestep: 400 !\n","Episode: 10, Reward: 243.0, Timestep: 450 !\n","Episode: 11, Reward: 245.45454545454547, Timestep: 50 !\n","Episode: 11, Reward: 245.45454545454547, Timestep: 100 !\n","Episode: 11, Reward: 245.45454545454547, Timestep: 150 !\n","Episode: 11, Reward: 245.45454545454547, Timestep: 200 !\n","Episode: 11, Reward: 245.45454545454547, Timestep: 250 !\n","Episode: 11, Reward: 245.45454545454547, Timestep: 300 !\n","Episode: 11, Reward: 245.45454545454547, Timestep: 350 !\n","Episode: 11, Reward: 245.45454545454547, Timestep: 400 !\n","Episode: 11, Reward: 245.45454545454547, Timestep: 450 !\n","Episode: 11, Reward: 245.45454545454547, Timestep: 500 !\n","Episode: 12, Reward: 252.5, Timestep: 50 !\n","Episode: 12, Reward: 252.5, Timestep: 100 !\n","Episode: 12, Reward: 252.5, Timestep: 150 !\n","Episode: 12, Reward: 252.5, Timestep: 200 !\n","Episode: 12, Reward: 252.5, Timestep: 250 !\n","Episode: 12, Reward: 252.5, Timestep: 300 !\n","Episode: 12, Reward: 252.5, Timestep: 350 !\n","Episode: 12, Reward: 252.5, Timestep: 400 !\n","Episode: 12, Reward: 252.5, Timestep: 450 !\n","Episode: 12, Reward: 252.5, Timestep: 500 !\n","Episode: 13, Reward: 255.3846153846154, Timestep: 50 !\n","Episode: 13, Reward: 255.3846153846154, Timestep: 100 !\n","Episode: 13, Reward: 255.3846153846154, Timestep: 150 !\n","Episode: 13, Reward: 255.3846153846154, Timestep: 200 !\n","Episode: 13, Reward: 255.3846153846154, Timestep: 250 !\n","Episode: 13, Reward: 255.3846153846154, Timestep: 300 !\n","Episode: 13, Reward: 255.3846153846154, Timestep: 350 !\n","Episode: 13, Reward: 255.3846153846154, Timestep: 400 !\n","Episode: 13, Reward: 255.3846153846154, Timestep: 450 !\n","Episode: 13, Reward: 255.3846153846154, Timestep: 500 !\n","Episode: 14, Reward: 260.7142857142857, Timestep: 50 !\n","Episode: 14, Reward: 260.7142857142857, Timestep: 100 !\n","Episode: 14, Reward: 260.7142857142857, Timestep: 150 !\n","Episode: 14, Reward: 260.7142857142857, Timestep: 200 !\n","Episode: 14, Reward: 260.7142857142857, Timestep: 250 !\n","Episode: 14, Reward: 260.7142857142857, Timestep: 300 !\n","Episode: 14, Reward: 260.7142857142857, Timestep: 350 !\n","Episode: 15, Reward: 257.3333333333333, Timestep: 50 !\n","Episode: 15, Reward: 257.3333333333333, Timestep: 100 !\n","Episode: 15, Reward: 257.3333333333333, Timestep: 150 !\n","Episode: 15, Reward: 257.3333333333333, Timestep: 200 !\n","Episode: 15, Reward: 257.3333333333333, Timestep: 250 !\n","Episode: 15, Reward: 257.3333333333333, Timestep: 300 !\n","Episode: 15, Reward: 257.3333333333333, Timestep: 350 !\n","Episode: 15, Reward: 257.3333333333333, Timestep: 400 !\n","Episode: 15, Reward: 257.3333333333333, Timestep: 450 !\n","Episode: 16, Reward: 256.25, Timestep: 50 !\n","Episode: 16, Reward: 256.25, Timestep: 100 !\n","Episode: 16, Reward: 256.25, Timestep: 150 !\n","Episode: 16, Reward: 256.25, Timestep: 200 !\n","Episode: 16, Reward: 256.25, Timestep: 250 !\n","Episode: 16, Reward: 256.25, Timestep: 300 !\n","Episode: 16, Reward: 256.25, Timestep: 350 !\n","Episode: 16, Reward: 256.25, Timestep: 400 !\n","Episode: 16, Reward: 256.25, Timestep: 450 !\n","Episode: 16, Reward: 256.25, Timestep: 500 !\n","Episode: 17, Reward: 255.2941176470588, Timestep: 50 !\n","Episode: 17, Reward: 255.2941176470588, Timestep: 100 !\n","Episode: 17, Reward: 255.2941176470588, Timestep: 150 !\n","Episode: 17, Reward: 255.2941176470588, Timestep: 200 !\n","Episode: 17, Reward: 255.2941176470588, Timestep: 250 !\n","Episode: 17, Reward: 255.2941176470588, Timestep: 300 !\n","Episode: 17, Reward: 255.2941176470588, Timestep: 350 !\n","Episode: 17, Reward: 255.2941176470588, Timestep: 400 !\n","Episode: 17, Reward: 255.2941176470588, Timestep: 450 !\n","Episode: 17, Reward: 255.2941176470588, Timestep: 500 !\n","Episode: 18, Reward: 256.1111111111111, Timestep: 50 !\n","Episode: 18, Reward: 256.1111111111111, Timestep: 100 !\n","Episode: 18, Reward: 256.1111111111111, Timestep: 150 !\n","Episode: 18, Reward: 256.1111111111111, Timestep: 200 !\n","Episode: 18, Reward: 256.1111111111111, Timestep: 250 !\n","Episode: 18, Reward: 256.1111111111111, Timestep: 300 !\n","Episode: 18, Reward: 256.1111111111111, Timestep: 350 !\n","Episode: 18, Reward: 256.1111111111111, Timestep: 400 !\n","Episode: 18, Reward: 256.1111111111111, Timestep: 450 !\n","Episode: 18, Reward: 256.1111111111111, Timestep: 500 !\n","Episode: 19, Reward: 254.21052631578948, Timestep: 50 !\n","Episode: 19, Reward: 254.21052631578948, Timestep: 100 !\n","Episode: 19, Reward: 254.21052631578948, Timestep: 150 !\n","Episode: 19, Reward: 254.21052631578948, Timestep: 200 !\n","Episode: 19, Reward: 254.21052631578948, Timestep: 250 !\n","Episode: 19, Reward: 254.21052631578948, Timestep: 300 !\n","Episode: 19, Reward: 254.21052631578948, Timestep: 350 !\n","Episode: 19, Reward: 254.21052631578948, Timestep: 400 !\n","Episode: 19, Reward: 254.21052631578948, Timestep: 450 !\n","Episode: 19, Reward: 254.21052631578948, Timestep: 500 !\n","running reward: 254.21 at episode 19, frame count 10000\n","Episode: 20, Reward: 256.5, Timestep: 50 !\n","Episode: 20, Reward: 256.5, Timestep: 100 !\n","Episode: 20, Reward: 256.5, Timestep: 150 !\n","Episode: 20, Reward: 256.5, Timestep: 200 !\n","Episode: 20, Reward: 256.5, Timestep: 250 !\n","Episode: 20, Reward: 256.5, Timestep: 300 !\n","Episode: 20, Reward: 256.5, Timestep: 350 !\n","Episode: 20, Reward: 256.5, Timestep: 400 !\n","Episode: 20, Reward: 256.5, Timestep: 450 !\n","Episode: 20, Reward: 256.5, Timestep: 500 !\n","Episode: 20, Reward: 256.5, Timestep: 550 !\n","Episode: 20, Reward: 256.5, Timestep: 600 !\n","Episode: 21, Reward: 270.95238095238096, Timestep: 50 !\n","Episode: 21, Reward: 270.95238095238096, Timestep: 100 !\n","Episode: 21, Reward: 270.95238095238096, Timestep: 150 !\n","Episode: 21, Reward: 270.95238095238096, Timestep: 200 !\n","Episode: 21, Reward: 270.95238095238096, Timestep: 250 !\n","Episode: 21, Reward: 270.95238095238096, Timestep: 300 !\n","Episode: 21, Reward: 270.95238095238096, Timestep: 350 !\n","Episode: 21, Reward: 270.95238095238096, Timestep: 400 !\n","Episode: 22, Reward: 272.27272727272725, Timestep: 50 !\n","Episode: 22, Reward: 272.27272727272725, Timestep: 100 !\n","Episode: 22, Reward: 272.27272727272725, Timestep: 150 !\n","Episode: 22, Reward: 272.27272727272725, Timestep: 200 !\n","Episode: 22, Reward: 272.27272727272725, Timestep: 250 !\n","Episode: 22, Reward: 272.27272727272725, Timestep: 300 !\n","Episode: 22, Reward: 272.27272727272725, Timestep: 350 !\n","Episode: 22, Reward: 272.27272727272725, Timestep: 400 !\n","Episode: 22, Reward: 272.27272727272725, Timestep: 450 !\n","Episode: 22, Reward: 272.27272727272725, Timestep: 500 !\n","Episode: 23, Reward: 272.60869565217394, Timestep: 50 !\n","Episode: 23, Reward: 272.60869565217394, Timestep: 100 !\n","Episode: 23, Reward: 272.60869565217394, Timestep: 150 !\n","Episode: 23, Reward: 272.60869565217394, Timestep: 200 !\n","Episode: 23, Reward: 272.60869565217394, Timestep: 250 !\n","Episode: 23, Reward: 272.60869565217394, Timestep: 300 !\n","Episode: 23, Reward: 272.60869565217394, Timestep: 350 !\n","Episode: 23, Reward: 272.60869565217394, Timestep: 400 !\n","Episode: 23, Reward: 272.60869565217394, Timestep: 450 !\n","Episode: 24, Reward: 270.0, Timestep: 50 !\n","Episode: 24, Reward: 270.0, Timestep: 100 !\n","Episode: 24, Reward: 270.0, Timestep: 150 !\n","Episode: 24, Reward: 270.0, Timestep: 200 !\n","Episode: 24, Reward: 270.0, Timestep: 250 !\n","Episode: 24, Reward: 270.0, Timestep: 300 !\n","Episode: 24, Reward: 270.0, Timestep: 350 !\n","Episode: 24, Reward: 270.0, Timestep: 400 !\n","Episode: 24, Reward: 270.0, Timestep: 450 !\n","Episode: 25, Reward: 268.8, Timestep: 50 !\n","Episode: 25, Reward: 268.8, Timestep: 100 !\n","Episode: 25, Reward: 268.8, Timestep: 150 !\n","Episode: 25, Reward: 268.8, Timestep: 200 !\n","Episode: 25, Reward: 268.8, Timestep: 250 !\n","Episode: 25, Reward: 268.8, Timestep: 300 !\n","Episode: 26, Reward: 262.6923076923077, Timestep: 50 !\n","Episode: 26, Reward: 262.6923076923077, Timestep: 100 !\n","Episode: 26, Reward: 262.6923076923077, Timestep: 150 !\n","Episode: 26, Reward: 262.6923076923077, Timestep: 200 !\n","Episode: 26, Reward: 262.6923076923077, Timestep: 250 !\n","Episode: 26, Reward: 262.6923076923077, Timestep: 300 !\n","Episode: 26, Reward: 262.6923076923077, Timestep: 350 !\n","Episode: 26, Reward: 262.6923076923077, Timestep: 400 !\n","Episode: 26, Reward: 262.6923076923077, Timestep: 450 !\n","Episode: 26, Reward: 262.6923076923077, Timestep: 500 !\n","Episode: 27, Reward: 261.85185185185185, Timestep: 50 !\n","Episode: 27, Reward: 261.85185185185185, Timestep: 100 !\n","Episode: 27, Reward: 261.85185185185185, Timestep: 150 !\n","Episode: 27, Reward: 261.85185185185185, Timestep: 200 !\n","Episode: 27, Reward: 261.85185185185185, Timestep: 250 !\n","Episode: 27, Reward: 261.85185185185185, Timestep: 300 !\n","Episode: 27, Reward: 261.85185185185185, Timestep: 350 !\n","Episode: 27, Reward: 261.85185185185185, Timestep: 400 !\n","Episode: 27, Reward: 261.85185185185185, Timestep: 450 !\n","Episode: 27, Reward: 261.85185185185185, Timestep: 500 !\n","Episode: 28, Reward: 264.2857142857143, Timestep: 50 !\n","Episode: 28, Reward: 264.2857142857143, Timestep: 100 !\n","Episode: 28, Reward: 264.2857142857143, Timestep: 150 !\n","Episode: 28, Reward: 264.2857142857143, Timestep: 200 !\n","Episode: 28, Reward: 264.2857142857143, Timestep: 250 !\n","Episode: 28, Reward: 264.2857142857143, Timestep: 300 !\n","Episode: 28, Reward: 264.2857142857143, Timestep: 350 !\n","Episode: 28, Reward: 264.2857142857143, Timestep: 400 !\n","Episode: 29, Reward: 263.44827586206895, Timestep: 50 !\n","Episode: 29, Reward: 263.44827586206895, Timestep: 100 !\n","Episode: 29, Reward: 263.44827586206895, Timestep: 150 !\n","Episode: 29, Reward: 263.44827586206895, Timestep: 200 !\n","Episode: 29, Reward: 263.44827586206895, Timestep: 250 !\n","Episode: 29, Reward: 263.44827586206895, Timestep: 300 !\n","Episode: 29, Reward: 263.44827586206895, Timestep: 350 !\n","Episode: 29, Reward: 263.44827586206895, Timestep: 400 !\n","Episode: 29, Reward: 263.44827586206895, Timestep: 450 !\n","Episode: 30, Reward: 264.3333333333333, Timestep: 50 !\n","Episode: 30, Reward: 264.3333333333333, Timestep: 100 !\n","Episode: 30, Reward: 264.3333333333333, Timestep: 150 !\n","Episode: 30, Reward: 264.3333333333333, Timestep: 200 !\n","Episode: 30, Reward: 264.3333333333333, Timestep: 250 !\n","Episode: 30, Reward: 264.3333333333333, Timestep: 300 !\n","Episode: 30, Reward: 264.3333333333333, Timestep: 350 !\n","Episode: 30, Reward: 264.3333333333333, Timestep: 400 !\n","Episode: 31, Reward: 262.9032258064516, Timestep: 50 !\n","Episode: 31, Reward: 262.9032258064516, Timestep: 100 !\n","Episode: 31, Reward: 262.9032258064516, Timestep: 150 !\n","Episode: 31, Reward: 262.9032258064516, Timestep: 200 !\n","Episode: 31, Reward: 262.9032258064516, Timestep: 250 !\n","Episode: 31, Reward: 262.9032258064516, Timestep: 300 !\n","Episode: 31, Reward: 262.9032258064516, Timestep: 350 !\n","Episode: 31, Reward: 262.9032258064516, Timestep: 400 !\n","Episode: 31, Reward: 262.9032258064516, Timestep: 450 !\n","Episode: 31, Reward: 262.9032258064516, Timestep: 500 !\n","Episode: 32, Reward: 260.9375, Timestep: 50 !\n","Episode: 32, Reward: 260.9375, Timestep: 100 !\n","Episode: 32, Reward: 260.9375, Timestep: 150 !\n","Episode: 32, Reward: 260.9375, Timestep: 200 !\n","Episode: 32, Reward: 260.9375, Timestep: 250 !\n","Episode: 32, Reward: 260.9375, Timestep: 300 !\n","Episode: 32, Reward: 260.9375, Timestep: 350 !\n","Episode: 32, Reward: 260.9375, Timestep: 400 !\n","Episode: 32, Reward: 260.9375, Timestep: 450 !\n","Episode: 32, Reward: 260.9375, Timestep: 500 !\n","Episode: 33, Reward: 262.72727272727275, Timestep: 50 !\n","Episode: 33, Reward: 262.72727272727275, Timestep: 100 !\n","Episode: 33, Reward: 262.72727272727275, Timestep: 150 !\n","Episode: 33, Reward: 262.72727272727275, Timestep: 200 !\n","Episode: 33, Reward: 262.72727272727275, Timestep: 250 !\n","Episode: 33, Reward: 262.72727272727275, Timestep: 300 !\n","Episode: 33, Reward: 262.72727272727275, Timestep: 350 !\n","Episode: 33, Reward: 262.72727272727275, Timestep: 400 !\n","Episode: 33, Reward: 262.72727272727275, Timestep: 450 !\n","Episode: 33, Reward: 262.72727272727275, Timestep: 500 !\n","Episode: 34, Reward: 262.3529411764706, Timestep: 50 !\n","Episode: 34, Reward: 262.3529411764706, Timestep: 100 !\n","Episode: 34, Reward: 262.3529411764706, Timestep: 150 !\n","Episode: 34, Reward: 262.3529411764706, Timestep: 200 !\n","Episode: 34, Reward: 262.3529411764706, Timestep: 250 !\n","Episode: 34, Reward: 262.3529411764706, Timestep: 300 !\n","Episode: 34, Reward: 262.3529411764706, Timestep: 350 !\n","Episode: 34, Reward: 262.3529411764706, Timestep: 400 !\n","Episode: 34, Reward: 262.3529411764706, Timestep: 450 !\n","Episode: 34, Reward: 262.3529411764706, Timestep: 500 !\n","Episode: 35, Reward: 260.57142857142856, Timestep: 50 !\n","Episode: 35, Reward: 260.57142857142856, Timestep: 100 !\n","Episode: 35, Reward: 260.57142857142856, Timestep: 150 !\n","Episode: 35, Reward: 260.57142857142856, Timestep: 200 !\n","Episode: 35, Reward: 260.57142857142856, Timestep: 250 !\n","Episode: 35, Reward: 260.57142857142856, Timestep: 300 !\n","Episode: 35, Reward: 260.57142857142856, Timestep: 350 !\n","Episode: 35, Reward: 260.57142857142856, Timestep: 400 !\n","Episode: 35, Reward: 260.57142857142856, Timestep: 450 !\n","Episode: 35, Reward: 260.57142857142856, Timestep: 500 !\n","Episode: 36, Reward: 259.44444444444446, Timestep: 50 !\n","Episode: 36, Reward: 259.44444444444446, Timestep: 100 !\n","Episode: 36, Reward: 259.44444444444446, Timestep: 150 !\n","Episode: 36, Reward: 259.44444444444446, Timestep: 200 !\n","Episode: 36, Reward: 259.44444444444446, Timestep: 250 !\n","Episode: 36, Reward: 259.44444444444446, Timestep: 300 !\n","Episode: 36, Reward: 259.44444444444446, Timestep: 350 !\n","Episode: 36, Reward: 259.44444444444446, Timestep: 400 !\n","Episode: 37, Reward: 257.56756756756755, Timestep: 50 !\n","Episode: 37, Reward: 257.56756756756755, Timestep: 100 !\n","Episode: 37, Reward: 257.56756756756755, Timestep: 150 !\n","Episode: 37, Reward: 257.56756756756755, Timestep: 200 !\n","Episode: 37, Reward: 257.56756756756755, Timestep: 250 !\n","Episode: 37, Reward: 257.56756756756755, Timestep: 300 !\n","Episode: 38, Reward: 254.73684210526315, Timestep: 50 !\n","Episode: 38, Reward: 254.73684210526315, Timestep: 100 !\n","Episode: 38, Reward: 254.73684210526315, Timestep: 150 !\n","Episode: 38, Reward: 254.73684210526315, Timestep: 200 !\n","Episode: 38, Reward: 254.73684210526315, Timestep: 250 !\n","Episode: 38, Reward: 254.73684210526315, Timestep: 300 !\n","Episode: 38, Reward: 254.73684210526315, Timestep: 350 !\n","Episode: 38, Reward: 254.73684210526315, Timestep: 400 !\n","Episode: 39, Reward: 250.51282051282053, Timestep: 50 !\n","Episode: 39, Reward: 250.51282051282053, Timestep: 100 !\n","Episode: 39, Reward: 250.51282051282053, Timestep: 150 !\n","Episode: 39, Reward: 250.51282051282053, Timestep: 200 !\n","Episode: 39, Reward: 250.51282051282053, Timestep: 250 !\n","Episode: 39, Reward: 250.51282051282053, Timestep: 300 !\n","Episode: 39, Reward: 250.51282051282053, Timestep: 350 !\n","Episode: 39, Reward: 250.51282051282053, Timestep: 400 !\n","Episode: 39, Reward: 250.51282051282053, Timestep: 450 !\n","Episode: 39, Reward: 250.51282051282053, Timestep: 500 !\n","Episode: 39, Reward: 250.51282051282053, Timestep: 550 !\n","Episode: 40, Reward: 254.75, Timestep: 50 !\n","Episode: 40, Reward: 254.75, Timestep: 100 !\n","Episode: 40, Reward: 254.75, Timestep: 150 !\n","Episode: 40, Reward: 254.75, Timestep: 200 !\n","Episode: 40, Reward: 254.75, Timestep: 250 !\n","Episode: 40, Reward: 254.75, Timestep: 300 !\n","running reward: 254.75 at episode 40, frame count 20000\n","Episode: 40, Reward: 254.75, Timestep: 350 !\n","Episode: 40, Reward: 254.75, Timestep: 400 !\n","Episode: 40, Reward: 254.75, Timestep: 450 !\n","Episode: 40, Reward: 254.75, Timestep: 500 !\n","Episode: 41, Reward: 253.65853658536585, Timestep: 50 !\n","Episode: 41, Reward: 253.65853658536585, Timestep: 100 !\n","Episode: 41, Reward: 253.65853658536585, Timestep: 150 !\n","Episode: 41, Reward: 253.65853658536585, Timestep: 200 !\n","Episode: 41, Reward: 253.65853658536585, Timestep: 250 !\n","Episode: 41, Reward: 253.65853658536585, Timestep: 300 !\n","Episode: 41, Reward: 253.65853658536585, Timestep: 350 !\n","Episode: 41, Reward: 253.65853658536585, Timestep: 400 !\n","Episode: 41, Reward: 253.65853658536585, Timestep: 450 !\n","Episode: 42, Reward: 251.1904761904762, Timestep: 50 !\n","Episode: 42, Reward: 251.1904761904762, Timestep: 100 !\n","Episode: 42, Reward: 251.1904761904762, Timestep: 150 !\n","Episode: 42, Reward: 251.1904761904762, Timestep: 200 !\n","Episode: 42, Reward: 251.1904761904762, Timestep: 250 !\n","Episode: 42, Reward: 251.1904761904762, Timestep: 300 !\n","Episode: 42, Reward: 251.1904761904762, Timestep: 350 !\n","Episode: 42, Reward: 251.1904761904762, Timestep: 400 !\n","Episode: 42, Reward: 251.1904761904762, Timestep: 450 !\n","Episode: 42, Reward: 251.1904761904762, Timestep: 500 !\n","Episode: 42, Reward: 251.1904761904762, Timestep: 550 !\n","Episode: 43, Reward: 253.02325581395348, Timestep: 50 !\n","Episode: 43, Reward: 253.02325581395348, Timestep: 100 !\n","Episode: 43, Reward: 253.02325581395348, Timestep: 150 !\n","Episode: 43, Reward: 253.02325581395348, Timestep: 200 !\n","Episode: 43, Reward: 253.02325581395348, Timestep: 250 !\n","Episode: 43, Reward: 253.02325581395348, Timestep: 300 !\n","Episode: 43, Reward: 253.02325581395348, Timestep: 350 !\n","Episode: 43, Reward: 253.02325581395348, Timestep: 400 !\n","Episode: 43, Reward: 253.02325581395348, Timestep: 450 !\n","Episode: 43, Reward: 253.02325581395348, Timestep: 500 !\n","Episode: 44, Reward: 253.4090909090909, Timestep: 50 !\n","Episode: 44, Reward: 253.4090909090909, Timestep: 100 !\n","Episode: 44, Reward: 253.4090909090909, Timestep: 150 !\n","Episode: 44, Reward: 253.4090909090909, Timestep: 200 !\n","Episode: 44, Reward: 253.4090909090909, Timestep: 250 !\n","Episode: 44, Reward: 253.4090909090909, Timestep: 300 !\n","Episode: 44, Reward: 253.4090909090909, Timestep: 350 !\n","Episode: 44, Reward: 253.4090909090909, Timestep: 400 !\n","Episode: 44, Reward: 253.4090909090909, Timestep: 450 !\n","Episode: 45, Reward: 253.11111111111111, Timestep: 50 !\n","Episode: 45, Reward: 253.11111111111111, Timestep: 100 !\n","Episode: 45, Reward: 253.11111111111111, Timestep: 150 !\n","Episode: 45, Reward: 253.11111111111111, Timestep: 200 !\n","Episode: 45, Reward: 253.11111111111111, Timestep: 250 !\n","Episode: 45, Reward: 253.11111111111111, Timestep: 300 !\n","Episode: 45, Reward: 253.11111111111111, Timestep: 350 !\n","Episode: 45, Reward: 253.11111111111111, Timestep: 400 !\n","Episode: 45, Reward: 253.11111111111111, Timestep: 450 !\n","Episode: 46, Reward: 251.7391304347826, Timestep: 50 !\n","Episode: 46, Reward: 251.7391304347826, Timestep: 100 !\n","Episode: 46, Reward: 251.7391304347826, Timestep: 150 !\n","Episode: 46, Reward: 251.7391304347826, Timestep: 200 !\n","Episode: 46, Reward: 251.7391304347826, Timestep: 250 !\n","Episode: 46, Reward: 251.7391304347826, Timestep: 300 !\n","Episode: 46, Reward: 251.7391304347826, Timestep: 350 !\n","Episode: 46, Reward: 251.7391304347826, Timestep: 400 !\n","Episode: 47, Reward: 251.48936170212767, Timestep: 50 !\n","Episode: 47, Reward: 251.48936170212767, Timestep: 100 !\n","Episode: 47, Reward: 251.48936170212767, Timestep: 150 !\n","Episode: 47, Reward: 251.48936170212767, Timestep: 200 !\n","Episode: 47, Reward: 251.48936170212767, Timestep: 250 !\n","Episode: 47, Reward: 251.48936170212767, Timestep: 300 !\n","Episode: 47, Reward: 251.48936170212767, Timestep: 350 !\n","Episode: 47, Reward: 251.48936170212767, Timestep: 400 !\n","Episode: 47, Reward: 251.48936170212767, Timestep: 450 !\n","Episode: 47, Reward: 251.48936170212767, Timestep: 500 !\n","Episode: 47, Reward: 251.48936170212767, Timestep: 550 !\n","Episode: 48, Reward: 251.45833333333334, Timestep: 50 !\n","Episode: 48, Reward: 251.45833333333334, Timestep: 100 !\n","Episode: 48, Reward: 251.45833333333334, Timestep: 150 !\n","Episode: 48, Reward: 251.45833333333334, Timestep: 200 !\n","Episode: 48, Reward: 251.45833333333334, Timestep: 250 !\n","Episode: 48, Reward: 251.45833333333334, Timestep: 300 !\n","Episode: 48, Reward: 251.45833333333334, Timestep: 350 !\n","Episode: 48, Reward: 251.45833333333334, Timestep: 400 !\n","Episode: 48, Reward: 251.45833333333334, Timestep: 450 !\n","Episode: 48, Reward: 251.45833333333334, Timestep: 500 !\n","Episode: 48, Reward: 251.45833333333334, Timestep: 550 !\n","Episode: 48, Reward: 251.45833333333334, Timestep: 600 !\n","Episode: 48, Reward: 251.45833333333334, Timestep: 650 !\n","Episode: 49, Reward: 256.53061224489795, Timestep: 50 !\n","Episode: 49, Reward: 256.53061224489795, Timestep: 100 !\n","Episode: 49, Reward: 256.53061224489795, Timestep: 150 !\n","Episode: 49, Reward: 256.53061224489795, Timestep: 200 !\n","Episode: 49, Reward: 256.53061224489795, Timestep: 250 !\n","Episode: 49, Reward: 256.53061224489795, Timestep: 300 !\n","Episode: 49, Reward: 256.53061224489795, Timestep: 350 !\n","Episode: 49, Reward: 256.53061224489795, Timestep: 400 !\n","Episode: 49, Reward: 256.53061224489795, Timestep: 450 !\n","Episode: 49, Reward: 256.53061224489795, Timestep: 500 !\n","Episode: 50, Reward: 256.0, Timestep: 50 !\n","Episode: 50, Reward: 256.0, Timestep: 100 !\n","Episode: 50, Reward: 256.0, Timestep: 150 !\n","Episode: 50, Reward: 256.0, Timestep: 200 !\n","Episode: 50, Reward: 256.0, Timestep: 250 !\n","Episode: 50, Reward: 256.0, Timestep: 300 !\n","Episode: 50, Reward: 256.0, Timestep: 350 !\n","Episode: 50, Reward: 256.0, Timestep: 400 !\n","Episode: 50, Reward: 256.0, Timestep: 450 !\n","Episode: 50, Reward: 256.0, Timestep: 500 !\n","Reward: 257.6470588235294 \n","Stopped at episode 51!\n"]}]},{"cell_type":"markdown","metadata":{"id":"K58TLcolHAOe"},"source":["**Here**, one of the stopping criteria is if `running_reward > 400`, by increasing this value, learning can be improved. Here, we have chosen the `episode_count > 50` by increasing this value the training time also increases.\n","\n","**Note:** The Deepmind paper trained for \"a total of 50 million frames( that is 38 days of game experience in total)\". However it will give good results at around 10 million frames which are processed in less than 24 hours on a modern machine.\n"]},{"cell_type":"markdown","metadata":{"id":"ILgJHu0WFQo0"},"source":["### Visualizations"]},{"cell_type":"markdown","source":["The agent's progress can be seen in the below video."],"metadata":{"id":"qS6ZZOrDET3w"}},{"cell_type":"code","source":["# Visualize training\n","env.close()\n","show_video()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":421},"id":"YwzPttqnBFdq","outputId":"b43ca1b9-93cd-4cdd-bf6f-889d161dbe74","executionInfo":{"status":"ok","timestamp":1720237192465,"user_tz":-330,"elapsed":1474,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<video alt=\"test\" autoplay\n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n","             </video>"]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"VHfHdGCP_n6Y"},"source":["### Please answer the questions below to complete the experiment:\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"VgSwVENIPcM6","executionInfo":{"status":"ok","timestamp":1720237499186,"user_tz":-330,"elapsed":606,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"source":["# @title  What is the significance of the discount factor (γ) in Q-learning? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Answer = \"It determines the impact of future rewards on the Q-values\" #@param [\"\",\"It controls the exploration rate\",\"It is irrelevant in Q-learning\", \"It influences the learning rate\", \"It determines the impact of future rewards on the Q-values\"]"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMzKSbLIgFzQ","executionInfo":{"status":"ok","timestamp":1720237545384,"user_tz":-330,"elapsed":625,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"source":["#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n","Complexity = \"Good and Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"DjcH1VWSFI2l","executionInfo":{"status":"ok","timestamp":1720237511799,"user_tz":-330,"elapsed":589,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"source":["#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n","Additional = \"good and challenging for me\" #@param {type:\"string\"}"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VBk_4VTAxCM","executionInfo":{"status":"ok","timestamp":1720237516225,"user_tz":-330,"elapsed":615,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"source":["#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"XH91cL1JWH7m","executionInfo":{"status":"ok","timestamp":1720237530998,"user_tz":-330,"elapsed":593,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"source":["#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Comments = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"z8xLqj7VWIKW","executionInfo":{"status":"ok","timestamp":1720237535095,"user_tz":-330,"elapsed":2,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"source":["#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n","Mentor_support = \"Very Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"FzAZHt1zw-Y-","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"outputId":"340dc184-5ff6-4661-f334-d759912b93c0","executionInfo":{"status":"ok","timestamp":1720237551165,"user_tz":-330,"elapsed":1901,"user":{"displayName":"hari","userId":"15787394902795857400"}}},"source":["#@title Run this cell to submit your notebook for grading { vertical-output: true }\n","try:\n","  if submission_id:\n","      return_id = submit_notebook()\n","      if return_id : submission_id = return_id\n","  else:\n","      print(\"Please complete the setup first.\")\n","except NameError:\n","  print (\"Please complete the setup first.\")"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Your submission is successful.\n","Ref Id: 1021\n","Date of submission:  06 Jul 2024\n","Time of submission:  09:15:43\n","View your submissions: https://aias-iisc.talentsprint.com/notebook_submissions\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1OtuFTKhwPBPgrkTYQL-UflTGzjU30ty7","timestamp":1720234584025}],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}